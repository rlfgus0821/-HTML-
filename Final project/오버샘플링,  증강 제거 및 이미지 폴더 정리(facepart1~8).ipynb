{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOSLMTtD7zMk6fsYnMAYvVR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nWWFtCb942Qy"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from IPython.display import display, Javascript"],"metadata":{"id":"bYuA0_uU5Y-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))"],"metadata":{"id":"BTDWX4CA5ZAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/final.csv')\n","    for col in ['annotations', 'equipment','bbox']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","    return df\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img"],"metadata":{"id":"Q7OOYlBu5ZDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 생성기\n","def create_data_generator(X, y, batch_size=32, is_training=True):\n","    def gen():\n","        for i in range(len(X)):\n","            img_path = X.iloc[i]\n","            if os.path.exists(img_path):  # 파일 존재 여부 확인\n","                img = load_and_preprocess_image(img_path)\n","                label = y.iloc[i]\n","                yield img, label\n","            else:\n","                print(f\"Skipping missing file: {img_path}\")  # 누락된 파일 정보 출력\n","\n","    dataset = tf.data.Dataset.from_generator(\n","        gen,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(), dtype=tf.float32)\n","        )\n","    )\n","\n","    if is_training:\n","        dataset = dataset.shuffle(buffer_size=len(X))\n","\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset"],"metadata":{"id":"RGkprmCU5ZFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 검증 데이터 생성기\n","def create_val_data_generator(X, y, directory, batch_size=32):\n","    return create_data_generator(X, y, directory, batch_size, is_training=False)"],"metadata":{"id":"glBqAc9qIMNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 생성 함수\n","def create_model(output_dim, model_type):\n","    base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    x_gap = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","    x_gmp = tf.keras.layers.GlobalMaxPooling2D()(base_model.output)\n","    x = tf.keras.layers.Concatenate()([x_gap, x_gmp])\n","    x = tf.keras.layers.Dense(256, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(0.4)(x)\n","\n","    if model_type == 'classification':\n","        output = tf.keras.layers.Dense(output_dim, activation='softmax')(x)\n","    else:  # regression\n","        output = tf.keras.layers.Dense(1)(x)\n","\n","    return tf.keras.Model(inputs=base_model.input, outputs=output)"],"metadata":{"id":"kwPLdGwn5ZHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 성능 시각화 함수\n","def plot_performance(history, metric_name, facepart, feature, model_type):\n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n","\n","    # Loss plot\n","    ax1.plot(history.history['loss'], label='Train Loss')\n","    ax1.plot(history.history['val_loss'], label='Validation Loss')\n","    ax1.set_title(f'{feature} Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    # Metric plot\n","    ax2.plot(history.history[metric_name], label=f'Train {metric_name.upper()}')\n","    ax2.plot(history.history[f'val_{metric_name}'], label=f'Validation {metric_name.upper()}')\n","    ax2.set_title(f'{feature} {metric_name.upper()}')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel(metric_name.upper())\n","    ax2.legend()\n","\n","    # ROC AUC plot\n","    ax3.plot(history.history['auc'], label='Train AUC')\n","    ax3.plot(history.history['val_auc'], label='Validation AUC')\n","    ax3.set_title(f'{feature} ROC AUC')\n","    ax3.set_xlabel('Epoch')\n","    ax3.set_ylabel('AUC')\n","    ax3.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_performance.png')\n","    plt.close()"],"metadata":{"id":"m1i_Midz5ZJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련 함수\n","def train_model(model, train_data, val_data, facepart, feature, model_type, epochs=50, batch_size=32):\n","    initial_lr = 1e-4\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n","\n","    if model_type == 'regression':\n","        loss = 'mean_squared_error'\n","        metrics = ['mae']\n","    else:  # classification\n","        loss = 'sparse_categorical_crossentropy'\n","        metrics = ['accuracy']\n","\n","    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_checkpoint_{{epoch:02d}}.keras',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='val_loss',\n","        mode='min',\n","        save_freq=10)\n","\n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[checkpoint_callback, reduce_lr, early_stopping]\n","    )\n","\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_final_model.keras')\n","    return history"],"metadata":{"id":"eYUxLTZL6Koc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 경로 가져오기 함수\n","def get_image_path(row, feature):\n","    facepart = row['facepart']\n","    filename = row['filename'].split('.')[0]\n","    class_value = row['annotations'][feature]\n","    source_type = row['source_type']\n","\n","    if facepart == 0:\n","        base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","    else:\n","        facepart_names = ['','forehead','glabellus','l_perocular','r_perocular','l_cheek','r_cheek','lip','chin']\n","        base_path = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/classified_cropped/{facepart_names[facepart]}/{feature}/{source_type}/{class_value}'\n","\n","    return str(os.path.join(base_path, f\"{filename}_{facepart}.jpg\"))\n","\n","# bbox 유효성 검증 함수\n","def valid_bbox(bbox):\n","    if bbox is None:\n","        return False\n","    if isinstance(bbox, list) and len(bbox) == 4:\n","        if bbox == ['None', 'None', 'None', 'None']:\n","            return False\n","        return all(isinstance(b, int) and b >= 0 for b in bbox)\n","    return False"],"metadata":{"id":"eb10nBVX6Ks_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# facepart별 모델 훈련 함수\n","def train_facepart_models(facepart, train_classification=True, train_regression=True):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    facepart_df = df[df['facepart'] == facepart]\n","    facepart_df = facepart_df[facepart_df['bbox'].apply(valid_bbox)]\n","\n","    if train_classification:\n","        for feature in facepart_df['annotations'].iloc[0].keys():\n","            y = facepart_df['annotations'].apply(lambda x: x.get(feature, None))\n","\n","            if y.nunique() > 1:\n","                print(f\"Starting classification training for facepart {facepart}, feature {feature}\")\n","\n","                # X = facepart_df.apply(lambda row: get_image_path(row, feature), axis=1)\n","\n","                train_data = facepart_df[facepart_df['source_type'] == 'train']\n","                val_data = facepart_df[facepart_df['source_type'] == 'val']\n","\n","                X_train = train_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                y_train = train_data['annotations'].apply(lambda x: x.get(feature, None))\n","                X_val = val_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                y_val = val_data['annotations'].apply(lambda x: x.get(feature, None))\n","\n","                train_generator = create_data_generator(X_train, y_train)\n","                val_generator = create_data_generator(X_val, y_val)\n","\n","                model = create_model(y.nunique(), 'classification')\n","                history = train_model(model, train_generator, val_generator, facepart, feature, 'classification')\n","                plot_performance(history, ['accuracy'], facepart, feature, 'classification')\n","\n","    if train_regression:\n","        regression_features = ['forehead_moisture', 'r_cheek_moisture', 'l_cheek_moisture', 'chin_moisture',\n","                               'chin_elasticity_R2', 'r_cheek_elasticity_R2', 'l_cheek_elasticity_R2',\n","                               'forehead_elasticity_R2', 'pigmentation_count', 'r_cheek_pore', 'l_cheek_pore']\n","\n","        for feature in regression_features:\n","            if feature in facepart_df['equipment'].iloc[0]:\n","                y = facepart_df['equipment'].apply(lambda x: x.get(feature, None))\n","\n","                if not y.isnull().all():\n","                    print(f\"Starting regression training for facepart {facepart}, feature {feature}\")\n","\n","                    # X = facepart_df.apply(lambda row: get_image_path(row, feature), axis=1)\n","\n","                    train_data = facepart_df[facepart_df['source_type'] == 'train']\n","                    val_data = facepart_df[facepart_df['source_type'] == 'val']\n","\n","                    X_train = train_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                    y_train = train_data['equipment'].apply(lambda x: x.get(feature, None))\n","                    X_val = val_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                    y_val = val_data['equipment'].apply(lambda x: x.get(feature, None))\n","\n","                    train_generator = create_data_generator(X_train, y_train)\n","                    val_generator = create_data_generator(X_val, y_val)\n","\n","                    model = create_model(1, 'regression')\n","                    history = train_model(model, train_generator, val_generator, facepart, feature, 'regression')\n","                    plot_performance(history, ['mae'], facepart, feature, 'regression')"],"metadata":{"id":"X6nNCskN6Ky1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 1-2, 2: 3-6, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = [1, 2]\n","    elif user_input == '2':\n","        facepart_range = [3, 4, 5, 6]\n","    elif user_input == '3':\n","        facepart_range = [7, 8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","    train_class = input(\"분류 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    train_reg = input(\"회귀 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    for facepart in facepart_range:\n","        train_facepart_models(facepart, train_classification=train_class, train_regression=train_reg)"],"metadata":{"id":"8k6lb5eG6K3F"},"execution_count":null,"outputs":[]}]}