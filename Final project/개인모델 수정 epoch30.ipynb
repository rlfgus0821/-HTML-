{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOA0De4EJTB0EAFyerHfETy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YAmrFtKwPhP1","executionInfo":{"status":"ok","timestamp":1721709803445,"user_tz":-540,"elapsed":9894,"user":{"displayName":"김길현","userId":"11058986998522215987"}},"outputId":"4ebd76f3-fab4-43eb-e94f-1f9768eeeca2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"n37bP1VzPi6I","executionInfo":{"status":"ok","timestamp":1721709820286,"user_tz":-540,"elapsed":16883,"user":{"displayName":"김길현","userId":"11058986998522215987"}},"outputId":"7a7136a2-dfd0-445e-abd4-3170b44b8342"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from IPython.display import display, Javascript"],"metadata":{"id":"A6rRKAe5Pi9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))\n","\n","# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv')\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","    df = df[df['split'] == 'Training']\n","    return preprocess_data(df)\n","\n","# 데이터 전처리\n","def preprocess_data(df):\n","    def process_annotations(anno):\n","        if isinstance(anno, dict):\n","            return {k: len(v) if isinstance(v, list) else v for k, v in anno.items()}\n","        return {}\n","\n","    df['annotations'] = df['annotations'].apply(process_annotations)\n","    df['equipment'] = df['equipment'].apply(lambda x: x if isinstance(x, dict) else {})\n","    return df\n","\n","# 오버샘플링 함수 (기존 코드 유지)\n","def oversample_data(X, y):\n","    ros = RandomOverSampler(random_state=42)\n","    X_resampled, y_resampled = ros.fit_resample(X.to_frame(), y)\n","    return X_resampled.iloc[:, 0], y_resampled\n","\n","# 클래스 가중치 계산 함수 (기존 코드 유지)\n","def compute_class_weights(y):\n","    classes = np.unique(y)\n","    weights = compute_class_weight('balanced', classes=classes, y=y)\n","    return dict(zip(classes, weights))\n","\n","# 데이터 증강 (기존 코드 유지)\n","def augment_data(image):\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","    return image\n","\n","# 이미지 로드 및 전처리 함수 (기존 코드 유지)\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img\n","\n","# 데이터 생성기 (기존 코드 유지)\n","def create_data_generator(X, y, directory, batch_size=32, is_training=True):\n","    def gen():\n","        for i in range(len(X)):\n","            img_path = X.iloc[i]\n","            if os.path.exists(img_path):  # 파일 존재 여부 확인\n","                img = load_and_preprocess_image(img_path)\n","                label = y.iloc[i]\n","                yield img, label\n","            else:\n","                print(f\"Skipping missing file: {img_path}\")  # 누락된 파일 정보 출력\n","\n","    dataset = tf.data.Dataset.from_generator(\n","        gen,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(), dtype=tf.float32)\n","        )\n","    )\n","\n","    if is_training:\n","        dataset = dataset.shuffle(buffer_size=len(X))\n","\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","# 검증 데이터 생성기 (기존 코드 유지)\n","def create_val_data_generator(X, y, directory, batch_size=32):\n","    return create_data_generator(X, y, directory, batch_size, is_training=False)\n","\n","# 모델 생성 함수 (기존 코드 유지)\n","def create_model(output_dim, model_type):\n","    base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    x_gap = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","    x_gmp = tf.keras.layers.GlobalMaxPooling2D()(base_model.output)\n","    x = tf.keras.layers.Concatenate()([x_gap, x_gmp])\n","    x = tf.keras.layers.Dense(256, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(0.4)(x)\n","\n","    if model_type == 'classification':\n","        output = tf.keras.layers.Dense(output_dim, activation='softmax')(x)\n","    else:  # regression\n","        output = tf.keras.layers.Dense(1)(x)\n","\n","    return tf.keras.Model(inputs=base_model.input, outputs=output)\n","\n","# 성능 시각화 함수 (기존 코드 유지)\n","def plot_performance(history, metric_name, facepart, feature, model_type):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","\n","    # Loss plot\n","    ax1.plot(history.history['loss'], label='Train Loss')\n","    ax1.plot(history.history['val_loss'], label='Validation Loss')\n","    ax1.set_title(f'{feature} Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    # Metric plot\n","    ax2.plot(history.history[metric_name], label=f'Train {metric_name.upper()}')\n","    ax2.plot(history.history[f'val_{metric_name}'], label=f'Validation {metric_name.upper()}')\n","    ax2.set_title(f'{feature} {metric_name.upper()}')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel(metric_name.upper())\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_performance.png')\n","    plt.close()\n","\n","# 모델 훈련 함수 (기존 코드 유지)\n","def train_model(model, train_data, val_data, facepart, feature, model_type, epochs=30, batch_size=32):\n","    initial_lr = 1e-4\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n","\n","    if model_type == 'regression':\n","        loss = 'mean_squared_error'\n","        metric = 'mae'\n","    else:  # classification\n","        loss = 'sparse_categorical_crossentropy'\n","        metric = 'accuracy'\n","\n","    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_checkpoint_{{epoch:02d}}.keras',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='loss',\n","        mode='min',\n","        save_freq=5)\n","\n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[checkpoint_callback, reduce_lr, early_stopping]\n","    )\n","\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_final_model.keras')\n","    return history\n","\n","# 이미지 경로 가져오기 함수 (요청하신 대로 사용)\n","def get_image_path(info, facepart, train_directory):\n","    if facepart == 0:\n","        filename = info['filename']\n","        path = f'/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터/{filename}'\n","        return path\n","    else:\n","        filename = info['filename'].split('.')[0]\n","        return str(os.path.join(train_directory, f\"{filename}_{facepart}.jpg\"))\n","\n","# facepart별 모델 훈련 함수 (수정됨)\n","def train_facepart_models(facepart, train_classification=True, train_regression=True):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    facepart_df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","    def valid_bbox(bbox):\n","        if bbox is None:\n","            return False\n","        if isinstance(bbox, list) and len(bbox) == 4:\n","            if bbox == ['None', 'None', 'None', 'None']:\n","                return False\n","            return all(isinstance(b, int) and b >= 0 for b in bbox)\n","        return False\n","\n","    facepart_df = facepart_df[facepart_df['images'].apply(lambda x: valid_bbox(x.get('bbox')))]\n","\n","    train_directory = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","    X = facepart_df['info'].apply(lambda x: get_image_path(x, facepart, train_directory))\n","\n","    if train_classification:\n","        for feature in facepart_df['annotations'].iloc[0].keys():\n","            if feature == 'acne' and facepart == 0:\n","                y = facepart_df['annotations'].apply(lambda x: x['acne'])\n","            else:\n","                y = facepart_df['annotations'].apply(lambda x: x.get(feature, None))\n","\n","            if y.nunique() > 1:\n","                print(f\"Starting classification training for facepart {facepart}, feature {feature}\")\n","\n","                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","                X_train_resampled, y_train_resampled = oversample_data(X_train, y_train)\n","\n","                train_generator = create_data_generator(X_train_resampled, y_train_resampled, train_directory)\n","                val_generator = create_val_data_generator(X_val, y_val, train_directory)\n","\n","                model = create_model(y.nunique(), 'classification')\n","                history = train_model(model, train_generator, val_generator, facepart, feature, 'classification')\n","                plot_performance(history, 'accuracy', facepart, feature, 'classification')\n","\n","    if train_regression:\n","        regression_features = ['forehead_moisture', 'r_cheek_moisture', 'l_cheek_moisture', 'chin_moisture',\n","                               'chin_elasticity_R2', 'r_cheek_elasticity_R2', 'l_cheek_elasticity_R2',\n","                               'forehead_elasticity_R2', 'pigmentation_count', 'r_cheek_pore', 'l_cheek_pore']\n","\n","        for feature in regression_features:\n","            if feature in facepart_df['equipment'].iloc[0]:\n","                y = facepart_df['equipment'].apply(lambda x: x.get(feature, None))\n","\n","                if not y.isnull().all():\n","                    print(f\"Starting regression training for facepart {facepart}, feature {feature}\")\n","\n","                    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","                    X_train_resampled, y_train_resampled = oversample_data(X_train, y_train)\n","\n","                    train_generator = create_data_generator(X_train_resampled, y_train_resampled, train_directory)\n","                    val_generator = create_val_data_generator(X_val, y_val, train_directory)\n","\n","                    model = create_model(1, 'regression')\n","                    history = train_model(model, train_generator, val_generator, facepart, feature, 'regression')\n","                    plot_performance(history, 'mae', facepart, feature, 'regression')\n","\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 3-6, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = [0, 1, 2]\n","    elif user_input == '2':\n","        facepart_range = [3, 4, 5, 6]\n","    elif user_input == '3':\n","        facepart_range = [7, 8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","    train_class = input(\"분류 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    train_reg = input(\"회귀 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    for facepart in facepart_range:\n","        train_facepart_models(facepart, train_classification=train_class, train_regression=train_reg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"8atY8lRwPouT","outputId":"e276636e-fb1d-44f7-826f-ccabef800f1b"},"execution_count":null,"outputs":[{"data":{"application/javascript":["\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing facepart 7\n","Starting classification training for facepart 7, feature lip_dryness\n","Epoch 1/100\n"]}]}]}