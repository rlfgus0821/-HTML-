{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9732,"status":"ok","timestamp":1721800831998,"user":{"displayName":"김길현","userId":"16642885004092978585"},"user_tz":-540},"id":"YAmrFtKwPhP1","outputId":"9758077f-e3be-4614-d808-61a22b692f31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":14925,"status":"ok","timestamp":1721727822409,"user":{"displayName":"김길현","userId":"16642885004092978585"},"user_tz":-540},"id":"n37bP1VzPi6I","outputId":"c0c62ed3-88f8-42ee-eb78-5a155b51afc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6rRKAe5Pi9q"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from IPython.display import display, Javascript"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"8atY8lRwPouT","outputId":"8f8c13f1-563d-46e1-ac32-854bf834ab64"},"outputs":[{"data":{"application/javascript":["\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 3-6, 3: 7-8): 3\n","분류 모델을 학습하시겠습니까? (y/n): y\n","회귀 모델을 학습하시겠습니까? (y/n): n\n","Processing facepart 7\n","Starting classification training for facepart 7, feature lip_dryness\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","16705208/16705208 [==============================] - 0s 0us/step\n","Epoch 1/30\n"]}],"source":["# 런타임 오류 방지 함수\n","# # 이 함수는 Colab의 런타임 연결이 끊기는 것을 방지하기 위해 60초마다 연결 버튼을 자동으로 클릭합니다.\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))\n","\n","# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    # '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv'에서 CSV 파일을 읽어 데이터프레임으로 로드합니다.\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv')\n","\n","    # 'info', 'images', 'annotations', 'equipment' 열의 문자열로 저장된 딕셔너리를 실제 딕셔너리로 변환합니다.\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # 'split' 열이 'Training'인 행만 선택합니다.\n","    df = df[df['split'] == 'Training']\n","\n","    # preprocess_data 함수를 호출하여 추가적인 전처리를 수행합니다.\n","    return preprocess_data(df)\n","\n","# 데이터 전처리\n","def preprocess_data(df):\n","    def process_annotations(anno):\n","        # annotations 열의 데이터를 처리합니다.\n","        if isinstance(anno, dict):\n","            # 값이 리스트인 경우에는 해당 리스트의 길이를 반환하고, 리스트가 아닌 경우에는 원래 값을 그대로 반환\n","            # facepart 0의 경우 'acne' 항목을 개수로 변환\n","            return {k: len(v) if isinstance(v, list) else v for k, v in anno.items()}\n","        return {}\n","\n","    # 각 행에 대해 annotations와 equipment를 처리합니다.\n","    df['annotations'] = df['annotations'].apply(process_annotations)\n","    # 'equipment' 열의 딕셔너리 value들 가져오기 딕셔너리가 아니고 None이면 빈 딕셔너리로 반환\n","    df['equipment'] = df['equipment'].apply(lambda x: x if isinstance(x, dict) else {})\n","    return df\n","\n","# 오버샘플링 함수\n","def oversample_data(X, y):\n","    # RandomOverSampler를 사용하여 샘플수가 적은 클래스의 샘플을 증가시킵니다.\n","    ros = RandomOverSampler(random_state=42)\n","    X_resampled, y_resampled = ros.fit_resample(X.to_frame(), y)\n","    return X_resampled.iloc[:, 0], y_resampled\n","\n","# 클래스 가중치 계산 함수\n","def compute_class_weights(y):\n","    # 클래스별 가중치를 계산합니다.\n","    classes = np.unique(y)\n","    weights = compute_class_weight('balanced', classes=classes, y=y)\n","    return dict(zip(classes, weights))\n","\n","# 데이터 증강\n","# 이미지 데이터 증강을 수행합니다.\n","def augment_data(image):\n","    image = tf.image.random_flip_up_down(image) # 상하 반전\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2) # 대비 조정\n","    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)) # 회전\n","    return image\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    # 주어진 경로(image_path)에서 이미지를 파일로 읽어오기\n","    img = tf.io.read_file(image_path)\n","    # 읽어온 파일을 JPEG 형식의 이미지로 디코딩합니다. 이미지는 3개의 채널(RGB)을 가집니다.\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    # 디코딩된 이미지를 224x224 크기로 리사이즈\n","    img = tf.image.resize(img, [224, 224])\n","    # EfficientNet 모델에 맞게 이미지를 전처리합니다. 이 단계는 이미지의 픽셀 값을 모델이 요구하는 형식(예: 정규화 등)으로 변환합니다.\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    # 전처리된 이미지를 반환\n","    return img\n","\n","# 데이터 제너레이터를 생성합니다.\n","# 이 함수는 이미지 경로와 레이블을 받아서 텐서플로우 데이터셋을 생성합니다.\n","def create_data_generator(X, y, directory, batch_size=32, is_training=True):\n","    # 이 함수는 데이터를 하나씩 생성하여 반환합니다.\n","    def gen():\n","        # X의 길이만큼 반복문을 실행합니다. 즉, 각 이미지 경로에 대해 반복합니다.\n","        for i in range(len(X)):\n","            # X에서 현재 인덱스 i에 해당하는 이미지 경로를 가져옵니다.\n","            img_path = X.iloc[i]\n","            if os.path.exists(img_path):  # 이미지 파일이 실제로 존재하는지 확인합니다.\n","                # 이미지 파일이 존재하면, load_and_preprocess_image 함수를 사용하여 이미지를 로드하고 전처리합니다\n","                img = load_and_preprocess_image(img_path)\n","                # y에서 현재 인덱스 i에 해당하는 레이블을 가져옵니다.\n","                label = y.iloc[i]\n","                # 전처리된 이미지와 레이블을 제너레이터의 출력으로 반환합니다.\n","                yield img, label\n","            # 이미지 파일이 존재하지 않을 경우에 대해 처리합니다.\n","            else:\n","                print(f\"Skipping missing file: {img_path}\")  # 누락된 파일 정보 출력\n","    # tf.data.Dataset.from_generator를 사용하여 제너레이터로부터 텐서플로우 데이터셋을 생성합니다.\n","    dataset = tf.data.Dataset.from_generator(\n","        # 데이터셋을 생성할 때 사용할 제너레이터 함수로 gen을 지정합니다.\n","        gen,\n","        # 데이터셋의 출력 타입과 형태를 정의\n","        output_signature=(\n","            # 이미지 텐서는 (224, 224, 3) 형태의 tf.float32 타입입니다.\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            # 레이블은 스칼라 tf.float32 타입입니다.\n","            tf.TensorSpec(shape=(), dtype=tf.float32)\n","        )\n","    )\n","    # is_training이 True일 경우\n","    if is_training:\n","        # 데이터셋을 셔플링합니다. 셔플링은 데이터의 순서를 무작위로 섞어줍니다.\n","        dataset = dataset.shuffle(buffer_size=len(X))\n","    # 데이터셋을 주어진 batch_size로 배치하고, .prefetch(tf.data.AUTOTUNE)을 사용하여 데이터 로딩과 모델 훈련을 병렬로 수행합니다.\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset # 최종적으로 생성된 데이터셋을 반환합니다\n","\n","# 검증 데이터 생성기\n","# is_training이 False여서 셔플링x\n","def create_val_data_generator(X, y, directory, batch_size=32):\n","    return create_data_generator(X, y, directory, batch_size, is_training=False)\n","\n","# 모델 생성 함수\n","# create_model이라는 함수를 정의합니다. 이 함수는 출력 차원(output_dim)과 모델 유형(model_type)을 인자로 받습니다.\n","def create_model(output_dim, model_type):\n","    # 'ImageNet'이라는 큰 데이터셋으로 학습된 가중치를 사용합니다.\n","    # EfficientNetB0 모델의 마지막 부분에는 이미지가 어떤 종류인지 분류하는 레이어가 있습니다.\n","    # include_top=False는 이 마지막 분류 레이어를 사용하지 않고 우리는 직접 새로운 분류 레이어를 추가할 것입니다.\n","    # 모델에 입력되는 이미지의 크기를 (224, 224, 3) -> 3은 색상 채널(RGB)을 의미\n","    base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","    # 기본 모델의 출력을 글로벌 평균 풀링 레이어를 통해 처리합니다. 이는 각 채널의 평균 값을 구합니다.\n","    # 각 특성 맵의 평균값을 계산하여 전체적인 특성을 포착\n","    # 색소침착의 전반적인 분포나 주름의 평균적인 정도를 감지하는 데 유용\n","    x_gap = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","\n","    # 기본 모델의 출력을 글로벌 맥스 풀링 레이어를 통해 처리합니다. 이는 각 채널의 최댓값을 구합니다.\n","    # 각 특성 맵의 최대값을 선택하여 가장 두드러진 특성을 포착\n","    # 가장 깊은 주름이나 가장 심한 색소침착 부위를 감지하는 데 효과적\n","    x_gmp = tf.keras.layers.GlobalMaxPooling2D()(base_model.output)\n","\n","    # 글로벌 평균 풀링과 글로벌 맥스 풀링의 출력을 병합합니다.\n","    x = tf.keras.layers.Concatenate()([x_gap, x_gmp])\n","    # 병합된 출력에 Dense 레이어를 추가하고, 256개의 유닛(뉴런)과 ReLU 활성화 함수를 사용합니다.\n","    x = tf.keras.layers.Dense(256, activation='relu')(x)\n","    # 40%의 노드를 랜덤하게 드롭아웃합니다. 이는 과적합을 방지하기 위함 입니다.\n","    x = tf.keras.layers.Dropout(0.4)(x)\n","\n","    if model_type == 'classification': # 분류\n","        # 분류 모델인 경우, Dense 레이어를 추가하여 output_dim 개수의 유닛(뉴런)과 소프트맥스 활성화 함수를 사용합니다. 이는 다중 클래스 분류를 위함\n","        output = tf.keras.layers.Dense(output_dim, activation='softmax')(x)\n","    else:  # 회귀\n","        # 회귀 모델인 경우, Dense 레이어를 추가하여 단일 유닛(뉴런)을 사용합니다.\n","        output = tf.keras.layers.Dense(1)(x)\n","    # 입력이 base_model.input이고 출력이 output인 케라스 모델 객체를 반환합니다.\n","    return tf.keras.Model(inputs=base_model.input, outputs=output)\n","\n","# 모델의 학습 과정을 시각화합니다.\n","# 훈련 및 검증 손실, 정확도(분류) 또는 MAE(회귀)를 시각화합니다.\n","# history 객체를 이용해 학습 손실(loss)과 평가 지표(metric)의 변화를 그래프로 그립니다.\n","def plot_performance(history, metric_name, facepart, feature, model_type):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","\n","    # 손실함수 plot\n","    ax1.plot(history.history['loss'], label='Train Loss')\n","    ax1.plot(history.history['val_loss'], label='Validation Loss')\n","    ax1.set_title(f'{feature} Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    # 정확도(분류) 또는 MAE(회귀) plot\n","    ax2.plot(history.history[metric_name], label=f'Train {metric_name.upper()}')\n","    ax2.plot(history.history[f'val_{metric_name}'], label=f'Validation {metric_name.upper()}')\n","    ax2.set_title(f'{feature} {metric_name.upper()}')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel(metric_name.upper())\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_performance.png')\n","    plt.close()\n","\n","# 모델 훈련 함수\n","# 모델을 학습시킵니다.\n","def train_model(model, train_data, val_data, facepart, feature, model_type, epochs=30, batch_size=32):\n","    # 초기 학습률을 설정\n","    initial_lr = 1e-4\n","    # Adam 옵티마이저를 초기화\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n","\n","    # 회귀 문제의 경우, 손실 함수는 평균 제곱 오차(mean_squared_error)이고, 평가 지표는 평균 절대 오차(mae)\n","    if model_type == 'regression':\n","        loss = 'mean_squared_error'\n","        metric = 'mae'\n","    # 분류 문제의 경우, 손실 함수는 희소 범주형 교차 엔트로피(sparse_categorical_crossentropy)이고, 평가 지표는 정확도(accuracy)\n","    else:  # classification\n","        loss = 'sparse_categorical_crossentropy'\n","        metric = 'accuracy'\n","    # 설정된 옵티마이저, 손실 함수, 평가 지표를 사용해서 모델을 컴파일\n","    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","    # 모델 체크포인트 콜백을 설정합니다. 이 콜백은 매 5 에포크마다 손실이 최소인 모델을 저장합니다.\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_checkpoint_{{epoch:02d}}.keras',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='loss',\n","        mode='min',\n","        save_freq=5)\n","\n","    # 학습 속도 감소 콜백을 설정합니다. 검증 손실(val_loss)이 개선되지 않으면 학습 속도를 줄입니다.\n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","    # 조기 종료 콜백을 설정합니다. 검증 손실이 10 에포크 동안 개선되지 않으면 학습을 중지하고, 가장 좋은 모델 가중치를 복원합니다.\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","    # 모델을 학습\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[checkpoint_callback, reduce_lr, early_stopping]\n","    )\n","    # 최종 학습된 모델을 저장\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_final_model.keras')\n","    return history\n","\n","# 이미지 경로 가져오기\n","def get_image_path(info, facepart, train_directory):\n","    if facepart == 0:\n","        filename = info['filename']\n","        path = f'/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터/{filename}'\n","        return path\n","    else:\n","        filename = info['filename'].split('.')[0]\n","        return str(os.path.join(train_directory, f\"{filename}_{facepart}.jpg\"))\n","\n","# facepart별 모델 훈련 함수\n","# 각 facepart에 대한 모델을 학습시킵니다.\n","def train_facepart_models(facepart, train_classification=True, train_regression=True):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    # facepart별 데이터프레임 생성\n","    facepart_df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","    # 유효한 bbox를 가진 행만 사용\n","    def valid_bbox(bbox):\n","        if bbox is None:\n","            return False\n","        if isinstance(bbox, list) and len(bbox) == 4:\n","            if bbox == ['None', 'None', 'None', 'None']:\n","                return False\n","            return all(isinstance(b, int) and b >= 0 for b in bbox)\n","        return False\n","    # bbox 유효성 검증\n","    facepart_df = facepart_df[facepart_df['images'].apply(lambda x: valid_bbox(x.get('bbox')))]\n","    # facepart 1~8 이미지 파일 경로\n","    train_directory = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","    # 이미지 경로 가져오기\n","    X = facepart_df['info'].apply(lambda x: get_image_path(x, facepart, train_directory))\n","\n","    if train_classification: # 분류\n","        # annotations컬럼의 키마다 진행\n","        for feature in facepart_df['annotations'].iloc[0].keys(): # facepart별 annotations 키값들 추출\n","            if feature == 'acne' and facepart == 0: # facepart0일 때\n","                # y(클래스)는 여드름 개수\n","                y = facepart_df['annotations'].apply(lambda x: x['acne'])\n","            else: # 나머지 facepart\n","                # y(클래스)는 annotations 컬럼의 키(feature) 값들\n","                y = facepart_df['annotations'].apply(lambda x: x.get(feature, None))\n","            # 클래스가 1개 초과일 경우 학습\n","            if y.nunique() > 1:\n","                print(f\"Starting classification training for facepart {facepart}, feature {feature}\")\n","                # 9:1 비율로 분할\n","                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","                # 샘플 수가 적은 클래스가 있어서 오버샘플링 적용\n","                X_train_resampled, y_train_resampled = oversample_data(X_train, y_train)\n","                # 학습, 검증 데이터 생성기 생성\n","                train_generator = create_data_generator(X_train_resampled, y_train_resampled, train_directory)\n","                val_generator = create_val_data_generator(X_val, y_val, train_directory)\n","\n","                model = create_model(y.nunique(), 'classification') # 분류 모델 생성\n","                history = train_model(model, train_generator, val_generator, facepart, feature, 'classification') # 모델 학습\n","                plot_performance(history, 'accuracy', facepart, feature, 'classification') # 학습 성능 시각화\n","\n","    if train_regression: # 회귀\n","        # # 회귀 모델 학습에 사용할 피처 리스트\n","        regression_features = ['forehead_moisture', 'r_cheek_moisture', 'l_cheek_moisture', 'chin_moisture',\n","                               'chin_elasticity_R2', 'r_cheek_elasticity_R2', 'l_cheek_elasticity_R2',\n","                               'forehead_elasticity_R2', 'pigmentation_count', 'r_cheek_pore', 'l_cheek_pore']\n","\n","        for feature in regression_features: # 피처리스트에 있는 피처별 진행\n","            if feature in facepart_df['equipment'].iloc[0]: # 현재 특징이 데이터프레임에 존재하는지 확인\n","                y = facepart_df['equipment'].apply(lambda x: x.get(feature, None)) # y 값을 피처로 설정\n","\n","                if not y.isnull().all(): # y 값이 모두 결측치가 아닌 경우에만 학습\n","                    print(f\"Starting regression training for facepart {facepart}, feature {feature}\") # 학습 시작 메시지 출력\n","                    # 9:1 비율로 분할\n","                    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","                    # 샘플 수가 적은 클래스가 있어서 오버샘플링 적용\n","                    X_train_resampled, y_train_resampled = oversample_data(X_train, y_train)\n","                    # 학습, 검증 데이터 생성기 생성\n","                    train_generator = create_data_generator(X_train_resampled, y_train_resampled, train_directory)\n","                    val_generator = create_val_data_generator(X_val, y_val, train_directory)\n","\n","                    model = create_model(1, 'regression')  # 회귀 모델 생성\n","                    history = train_model(model, train_generator, val_generator, facepart, feature, 'regression') # 모델 학습\n","                    plot_performance(history, 'mae', facepart, feature, 'regression') # 학습 성능 시각화\n","\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 3-6, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = [0, 1, 2]\n","    elif user_input == '2':\n","        facepart_range = [3, 4, 5, 6]\n","    elif user_input == '3':\n","        facepart_range = [7, 8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","    train_class = input(\"분류 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    train_reg = input(\"회귀 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    for facepart in facepart_range:\n","        train_facepart_models(facepart, train_classification=train_class, train_regression=train_reg)"]},{"cell_type":"markdown","metadata":{"id":"kQ9qVw7xoOdf"},"source":["# 테스트"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fikFDd_YoPgS"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","def load_and_preprocess_data(split='Validation'):\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv')\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","    df = df[df['split'] == split]\n","    return df\n","\n","def get_image_path(info, facepart):\n","    filename = info['filename'].split('.')[0]\n","    return f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Validation_cropped/{facepart}/{filename}_{facepart}.jpg'\n","\n","# 이미지 로드 및 전처리 함수 (에러 처리 추가)\n","def load_and_preprocess_image(image_path):\n","    if not os.path.exists(image_path):\n","        print(f\"파일을 찾을 수 없습니다: {image_path}\")\n","        return None\n","    try:\n","        img = tf.io.read_file(image_path)\n","        img = tf.image.decode_jpeg(img, channels=3)\n","        img = tf.image.resize(img, [224, 224])\n","        img = tf.keras.applications.efficientnet.preprocess_input(img)\n","        return img\n","    except tf.errors.InvalidArgumentError:\n","        print(f\"이미지를 처리할 수 없습니다: {image_path}\")\n","        return None\n","\n","# 데이터셋 생성 함수 (에러 처리 추가)\n","def create_dataset(X, y):\n","    def generator():\n","        for image_path, label in zip(X, y):\n","            img = load_and_preprocess_image(image_path)\n","            if img is not None:\n","                yield img, label\n","\n","    return tf.data.Dataset.from_generator(\n","        generator,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(), dtype=tf.int32)\n","        )\n","    )\n","\n","# 성능 평가 및 시각화 함수\n","def evaluate_model(model, dataset, y, feature, facepart):\n","    # 예측\n","    y_true = []\n","    y_pred = []\n","    for images, labels in dataset:\n","        predictions = model.predict(images)\n","        y_true.extend(labels.numpy())\n","        y_pred.extend(np.argmax(predictions, axis=1))\n","\n","    # 분류 리포트 출력\n","    print(classification_report(y_true, y_pred))\n","\n","    # 혼동 행렬 시각화\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(10, 8))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title(f'Confusion Matrix - Facepart {facepart}, Feature {feature}')\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_confusion_matrix.png')\n","    plt.close()\n","\n","# 메인 실행 코드\n","if __name__ == \"__main__\":\n","    facepart = 7\n","    df = load_and_preprocess_data('Validation')\n","    # 제거할 파일명 리스트\n","    filenames_to_remove = ['0615_01_L15.jpg', '0615_01_R30.jpg', '0627_01_Ft.jpg']\n","\n","    # 조건에 맞는 행을 제거\n","    df = df[~df['info'].apply(lambda x: x['filename'] in filenames_to_remove)]\n","    facepart_df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","    for feature in facepart_df['annotations'].iloc[0].keys():\n","        print(f\"Evaluating feature: {feature}\")\n","\n","        # 데이터 준비\n","        X = facepart_df['info'].apply(lambda x: get_image_path(x, facepart))\n","        y = facepart_df['annotations'].apply(lambda x: x.get(feature, None))\n","\n","        # 유효한 데이터만 선택\n","        valid_indices = ~y.isnull()\n","        X = X[valid_indices]\n","        y = y[valid_indices]\n","\n","        if y.nunique() > 1:\n","            # 모델 로드\n","            model_path = f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_7_classification_checkpoint_01.keras'\n","            if not os.path.exists(model_path):\n","                print(f\"모델 파일을 찾을 수 없습니다: {model_path}\")\n","                continue\n","            model = tf.keras.models.load_model(model_path)\n","\n","            # 데이터셋 생성\n","            dataset = create_dataset(X.tolist(), y.tolist())\n","            dataset = dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","            # 모델 평가\n","            evaluate_model(model, dataset, y, feature, facepart)\n","        else:\n","            print(f\"Skipping {feature} due to insufficient classes\")"]},{"cell_type":"markdown","source":["# 데이터 전처리"],"metadata":{"id":"jXsfLMKBvBg2"}},{"cell_type":"code","source":["df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/json_to_df_result.csv')\n","for col in ['annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)"],"metadata":{"id":"buNN6L6IVKlK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnE9rapkWXRV","executionInfo":{"status":"ok","timestamp":1721801213975,"user_tz":-540,"elapsed":920,"user":{"displayName":"김길현","userId":"16642885004092978585"}},"outputId":"7a0b5123-69ad-4ada-81a2-74ee20fcd76d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["112905"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["df['source_type'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6uk7I2kWcxs","executionInfo":{"status":"ok","timestamp":1721801254601,"user_tz":-540,"elapsed":869,"user":{"displayName":"김길현","userId":"16642885004092978585"}},"outputId":"67ab4e18-f5dd-4dbd-acfd-d193b5d254ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["source_type\n","Training      100386\n","Validation     12519\n","Name: count, dtype: int64"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/라벨링 데이터/'\n","face_list = ['face','forehead','glabellus','l_perocular','r_perocular','l_cheek','r_cheek','lip','chin']\n","for no, facepart in zip(range(9),face_list):\n","    new = df[df['facepart']== no]\n","    new.to_csv(base_path + f'{facepart}_origin.csv')\n","    new.dropna(inplace=True)\n","    new.to_csv(base_path + f'{facepart}.csv')\n","    print(facepart)\n","    new.info()\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"IAc23EvyXeLZ","executionInfo":{"status":"ok","timestamp":1721802483575,"user_tz":-540,"elapsed":6714,"user":{"displayName":"김길현","userId":"16642885004092978585"}},"outputId":"49409a4e-aef0-4c5b-bba9-f973fed3956d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["face\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12545 entries, 0 to 112896\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12545 non-null  object\n"," 1   annotations  12545 non-null  object\n"," 2   equipment    12545 non-null  object\n"," 3   filename     12545 non-null  object\n"," 4   id           12545 non-null  int64 \n"," 5   gender       12545 non-null  object\n"," 6   age          12545 non-null  int64 \n"," 7   date         12545 non-null  object\n"," 8   skin_type    12545 non-null  int64 \n"," 9   sensitive    12545 non-null  int64 \n"," 10  device       12545 non-null  int64 \n"," 11  width        12545 non-null  int64 \n"," 12  height       12545 non-null  int64 \n"," 13  angle        12545 non-null  int64 \n"," 14  facepart     12545 non-null  int64 \n"," 15  bbox         12545 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["forehead\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12504 entries, 1 to 112897\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12504 non-null  object\n"," 1   annotations  12504 non-null  object\n"," 2   equipment    12504 non-null  object\n"," 3   filename     12504 non-null  object\n"," 4   id           12504 non-null  int64 \n"," 5   gender       12504 non-null  object\n"," 6   age          12504 non-null  int64 \n"," 7   date         12504 non-null  object\n"," 8   skin_type    12504 non-null  int64 \n"," 9   sensitive    12504 non-null  int64 \n"," 10  device       12504 non-null  int64 \n"," 11  width        12504 non-null  int64 \n"," 12  height       12504 non-null  int64 \n"," 13  angle        12504 non-null  int64 \n"," 14  facepart     12504 non-null  int64 \n"," 15  bbox         12504 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["glabellus\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12497 entries, 2 to 112898\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12497 non-null  object\n"," 1   annotations  12497 non-null  object\n"," 2   equipment    12497 non-null  object\n"," 3   filename     12497 non-null  object\n"," 4   id           12497 non-null  int64 \n"," 5   gender       12497 non-null  object\n"," 6   age          12497 non-null  int64 \n"," 7   date         12497 non-null  object\n"," 8   skin_type    12497 non-null  int64 \n"," 9   sensitive    12497 non-null  int64 \n"," 10  device       12497 non-null  int64 \n"," 11  width        12497 non-null  int64 \n"," 12  height       12497 non-null  int64 \n"," 13  angle        12497 non-null  int64 \n"," 14  facepart     12497 non-null  int64 \n"," 15  bbox         12497 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["l_perocular\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 10034 entries, 3 to 112899\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  10034 non-null  object\n"," 1   annotations  10034 non-null  object\n"," 2   equipment    10034 non-null  object\n"," 3   filename     10034 non-null  object\n"," 4   id           10034 non-null  int64 \n"," 5   gender       10034 non-null  object\n"," 6   age          10034 non-null  int64 \n"," 7   date         10034 non-null  object\n"," 8   skin_type    10034 non-null  int64 \n"," 9   sensitive    10034 non-null  int64 \n"," 10  device       10034 non-null  int64 \n"," 11  width        10034 non-null  int64 \n"," 12  height       10034 non-null  int64 \n"," 13  angle        10034 non-null  int64 \n"," 14  facepart     10034 non-null  int64 \n"," 15  bbox         10034 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.3+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["r_perocular\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 10050 entries, 4 to 112891\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  10050 non-null  object\n"," 1   annotations  10050 non-null  object\n"," 2   equipment    10050 non-null  object\n"," 3   filename     10050 non-null  object\n"," 4   id           10050 non-null  int64 \n"," 5   gender       10050 non-null  object\n"," 6   age          10050 non-null  int64 \n"," 7   date         10050 non-null  object\n"," 8   skin_type    10050 non-null  int64 \n"," 9   sensitive    10050 non-null  int64 \n"," 10  device       10050 non-null  int64 \n"," 11  width        10050 non-null  int64 \n"," 12  height       10050 non-null  int64 \n"," 13  angle        10050 non-null  int64 \n"," 14  facepart     10050 non-null  int64 \n"," 15  bbox         10050 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.3+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["l_cheek\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12304 entries, 5 to 112901\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12304 non-null  object\n"," 1   annotations  12304 non-null  object\n"," 2   equipment    12304 non-null  object\n"," 3   filename     12304 non-null  object\n"," 4   id           12304 non-null  int64 \n"," 5   gender       12304 non-null  object\n"," 6   age          12304 non-null  int64 \n"," 7   date         12304 non-null  object\n"," 8   skin_type    12304 non-null  int64 \n"," 9   sensitive    12304 non-null  int64 \n"," 10  device       12304 non-null  int64 \n"," 11  width        12304 non-null  int64 \n"," 12  height       12304 non-null  int64 \n"," 13  angle        12304 non-null  int64 \n"," 14  facepart     12304 non-null  int64 \n"," 15  bbox         12304 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["r_cheek\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12304 entries, 6 to 112902\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12304 non-null  object\n"," 1   annotations  12304 non-null  object\n"," 2   equipment    12304 non-null  object\n"," 3   filename     12304 non-null  object\n"," 4   id           12304 non-null  int64 \n"," 5   gender       12304 non-null  object\n"," 6   age          12304 non-null  int64 \n"," 7   date         12304 non-null  object\n"," 8   skin_type    12304 non-null  int64 \n"," 9   sensitive    12304 non-null  int64 \n"," 10  device       12304 non-null  int64 \n"," 11  width        12304 non-null  int64 \n"," 12  height       12304 non-null  int64 \n"," 13  angle        12304 non-null  int64 \n"," 14  facepart     12304 non-null  int64 \n"," 15  bbox         12304 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["lip\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12522 entries, 7 to 112903\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12522 non-null  object\n"," 1   annotations  12522 non-null  object\n"," 2   equipment    12522 non-null  object\n"," 3   filename     12522 non-null  object\n"," 4   id           12522 non-null  int64 \n"," 5   gender       12522 non-null  object\n"," 6   age          12522 non-null  int64 \n"," 7   date         12522 non-null  object\n"," 8   skin_type    12522 non-null  int64 \n"," 9   sensitive    12522 non-null  int64 \n"," 10  device       12522 non-null  int64 \n"," 11  width        12522 non-null  int64 \n"," 12  height       12522 non-null  int64 \n"," 13  angle        12522 non-null  int64 \n"," 14  facepart     12522 non-null  int64 \n"," 15  bbox         12522 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-52-d35697e3a93d>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  new.dropna(inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["chin\n","<class 'pandas.core.frame.DataFrame'>\n","Index: 12545 entries, 8 to 112904\n","Data columns (total 16 columns):\n"," #   Column       Non-Null Count  Dtype \n","---  ------       --------------  ----- \n"," 0   source_type  12545 non-null  object\n"," 1   annotations  12545 non-null  object\n"," 2   equipment    12545 non-null  object\n"," 3   filename     12545 non-null  object\n"," 4   id           12545 non-null  int64 \n"," 5   gender       12545 non-null  object\n"," 6   age          12545 non-null  int64 \n"," 7   date         12545 non-null  object\n"," 8   skin_type    12545 non-null  int64 \n"," 9   sensitive    12545 non-null  int64 \n"," 10  device       12545 non-null  int64 \n"," 11  width        12545 non-null  int64 \n"," 12  height       12545 non-null  int64 \n"," 13  angle        12545 non-null  int64 \n"," 14  facepart     12545 non-null  int64 \n"," 15  bbox         12545 non-null  object\n","dtypes: int64(9), object(7)\n","memory usage: 1.6+ MB\n","\n"]}]},{"cell_type":"code","source":["chin_df = pd.read_csv(base_path + 'chin.csv', index_col=0)\n","for col in ['annotations','equipment']:\n","        chin_df[col] = chin_df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","chin_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":152},"collapsed":true,"id":"wvbxCrgqqUtU","executionInfo":{"status":"ok","timestamp":1721807256400,"user_tz":-540,"elapsed":1768,"user":{"displayName":"김길현","userId":"16642885004092978585"}},"outputId":"c1b8ae23-94df-41b1-bb41-69d95b2de8c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  source_type          annotations  \\\n","8  Validation  {'chin_sagging': 1}   \n","\n","                                           equipment        filename  id  \\\n","8  {'chin_moisture': 78.667, 'chin_elasticity_R0'...  0001_01_Fb.jpg   1   \n","\n","  gender  age        date  skin_type  sensitive  device  width  height  angle  \\\n","8      F   13  2023-08-17          0          0       0   2136    3216      2   \n","\n","   facepart                     bbox  \n","8         8  [396, 2671, 1749, 3144]  "],"text/html":["\n","  <div id=\"df-6c42d039-5823-49ba-a9ef-b1c0ce51b584\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_type</th>\n","      <th>annotations</th>\n","      <th>equipment</th>\n","      <th>filename</th>\n","      <th>id</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>date</th>\n","      <th>skin_type</th>\n","      <th>sensitive</th>\n","      <th>device</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>angle</th>\n","      <th>facepart</th>\n","      <th>bbox</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>Validation</td>\n","      <td>{'chin_sagging': 1}</td>\n","      <td>{'chin_moisture': 78.667, 'chin_elasticity_R0'...</td>\n","      <td>0001_01_Fb.jpg</td>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>13</td>\n","      <td>2023-08-17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2136</td>\n","      <td>3216</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>[396, 2671, 1749, 3144]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c42d039-5823-49ba-a9ef-b1c0ce51b584')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6c42d039-5823-49ba-a9ef-b1c0ce51b584 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6c42d039-5823-49ba-a9ef-b1c0ce51b584');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"chin_df","repr_error":"0"}},"metadata":{},"execution_count":156}]},{"cell_type":"code","source":["acne_list = []\n","# wrinkle_list = []\n","for d in chin_df['annotations']:\n","    acne_list.append(d['chin_sagging'])\n","    # wrinkle_list.append(d['r_cheek_pigmentation'])\n","chin_df['sagging'] = acne_list\n","# r_cheek_df['pigmentation'] = wrinkle_list\n","chin_df.head(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":152},"id":"zXQ89dvIq1wi","executionInfo":{"status":"ok","timestamp":1721807283560,"user_tz":-540,"elapsed":842,"user":{"displayName":"김길현","userId":"16642885004092978585"}},"outputId":"3e8b9f19-8983-4534-f16c-e59c30d0fa72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  source_type          annotations  \\\n","8  Validation  {'chin_sagging': 1}   \n","\n","                                           equipment        filename  id  \\\n","8  {'chin_moisture': 78.667, 'chin_elasticity_R0'...  0001_01_Fb.jpg   1   \n","\n","  gender  age        date  skin_type  sensitive  device  width  height  angle  \\\n","8      F   13  2023-08-17          0          0       0   2136    3216      2   \n","\n","   facepart                     bbox  sagging  \n","8         8  [396, 2671, 1749, 3144]        1  "],"text/html":["\n","  <div id=\"df-d9be7479-4233-4d0b-a329-d28f2bb47e5e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source_type</th>\n","      <th>annotations</th>\n","      <th>equipment</th>\n","      <th>filename</th>\n","      <th>id</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>date</th>\n","      <th>skin_type</th>\n","      <th>sensitive</th>\n","      <th>device</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>angle</th>\n","      <th>facepart</th>\n","      <th>bbox</th>\n","      <th>sagging</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8</th>\n","      <td>Validation</td>\n","      <td>{'chin_sagging': 1}</td>\n","      <td>{'chin_moisture': 78.667, 'chin_elasticity_R0'...</td>\n","      <td>0001_01_Fb.jpg</td>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>13</td>\n","      <td>2023-08-17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2136</td>\n","      <td>3216</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>[396, 2671, 1749, 3144]</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9be7479-4233-4d0b-a329-d28f2bb47e5e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d9be7479-4233-4d0b-a329-d28f2bb47e5e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d9be7479-4233-4d0b-a329-d28f2bb47e5e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"chin_df","repr_error":"0"}},"metadata":{},"execution_count":157}]},{"cell_type":"code","source":["chin_df.to_csv(base_path + 'chin.csv')"],"metadata":{"id":"SWHeQJb1rUAD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["face_list = ['face','forehead','glabellus','l_perocular','r_perocular','l_cheek','r_cheek','lip','chin']\n","base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/라벨링 데이터/'\n","df = pd.read_csv(base_path + 'l_cheek.csv')\n","df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"752azUlyt0zv","executionInfo":{"status":"ok","timestamp":1721807547272,"user_tz":-540,"elapsed":1166,"user":{"displayName":"김길현","userId":"16642885004092978585"}},"outputId":"b7c7ab0b-2c53-47ec-bee6-be34bf5a3c9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0 source_type                                     annotations  \\\n","0           5  Validation  {'l_cheek_pore': 2, 'l_cheek_pigmentation': 3}   \n","1          14  Validation  {'l_cheek_pore': 2, 'l_cheek_pigmentation': 3}   \n","2          23  Validation  {'l_cheek_pore': 2, 'l_cheek_pigmentation': 3}   \n","\n","                                           equipment        filename  id  \\\n","0  {'l_cheek_moisture': 71.667, 'l_cheek_elastici...  0001_01_Fb.jpg   1   \n","1  {'l_cheek_moisture': 71.667, 'l_cheek_elastici...  0001_01_Ft.jpg   1   \n","2  {'l_cheek_moisture': 71.667, 'l_cheek_elastici...   0001_01_F.jpg   1   \n","\n","  gender  age        date  skin_type  sensitive  device  width  height  angle  \\\n","0      F   13  2023-08-17          0          0       0   2136    3216      2   \n","1      F   13  2023-08-17          0          0       0   2136    3216      1   \n","2      F   13  2023-08-17          0          0       0   2136    3216      0   \n","\n","   facepart                    bbox  pore  pigmentation  \n","0         5  [327, 1879, 829, 2538]     2             3  \n","1         5  [175, 1361, 788, 1964]     2             3  \n","2         5  [257, 1680, 832, 2355]     2             3  "],"text/html":["\n","  <div id=\"df-7a169dbd-0c2c-4e28-872d-7ecc2881425a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>source_type</th>\n","      <th>annotations</th>\n","      <th>equipment</th>\n","      <th>filename</th>\n","      <th>id</th>\n","      <th>gender</th>\n","      <th>age</th>\n","      <th>date</th>\n","      <th>skin_type</th>\n","      <th>sensitive</th>\n","      <th>device</th>\n","      <th>width</th>\n","      <th>height</th>\n","      <th>angle</th>\n","      <th>facepart</th>\n","      <th>bbox</th>\n","      <th>pore</th>\n","      <th>pigmentation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5</td>\n","      <td>Validation</td>\n","      <td>{'l_cheek_pore': 2, 'l_cheek_pigmentation': 3}</td>\n","      <td>{'l_cheek_moisture': 71.667, 'l_cheek_elastici...</td>\n","      <td>0001_01_Fb.jpg</td>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>13</td>\n","      <td>2023-08-17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2136</td>\n","      <td>3216</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>[327, 1879, 829, 2538]</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14</td>\n","      <td>Validation</td>\n","      <td>{'l_cheek_pore': 2, 'l_cheek_pigmentation': 3}</td>\n","      <td>{'l_cheek_moisture': 71.667, 'l_cheek_elastici...</td>\n","      <td>0001_01_Ft.jpg</td>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>13</td>\n","      <td>2023-08-17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2136</td>\n","      <td>3216</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>[175, 1361, 788, 1964]</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23</td>\n","      <td>Validation</td>\n","      <td>{'l_cheek_pore': 2, 'l_cheek_pigmentation': 3}</td>\n","      <td>{'l_cheek_moisture': 71.667, 'l_cheek_elastici...</td>\n","      <td>0001_01_F.jpg</td>\n","      <td>1</td>\n","      <td>F</td>\n","      <td>13</td>\n","      <td>2023-08-17</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2136</td>\n","      <td>3216</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>[257, 1680, 832, 2355]</td>\n","      <td>2</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a169dbd-0c2c-4e28-872d-7ecc2881425a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7a169dbd-0c2c-4e28-872d-7ecc2881425a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7a169dbd-0c2c-4e28-872d-7ecc2881425a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3d27c6d5-b2d6-46b9-bc8c-07f3463cc209\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d27c6d5-b2d6-46b9-bc8c-07f3463cc209')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3d27c6d5-b2d6-46b9-bc8c-07f3463cc209 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 12304,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32580,\n        \"min\": 5,\n        \"max\": 112901,\n        \"num_unique_values\": 12304,\n        \"samples\": [\n          82445,\n          6710,\n          84299\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Training\",\n          \"Validation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotations\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"{'l_cheek_pore': 0, 'l_cheek_pigmentation': 0}\",\n          \"{'l_cheek_pore': 2, 'l_cheek_pigmentation': 4}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"equipment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 966,\n        \"samples\": [\n          \"{'l_cheek_moisture': 76.333, 'l_cheek_elasticity_R0': 0.355, 'l_cheek_elasticity_R1': 0.142, 'l_cheek_elasticity_R2': 0.6, 'l_cheek_elasticity_R3': 0.406, 'l_cheek_elasticity_R4': 0.204, 'l_cheek_elasticity_R5': 0.502, 'l_cheek_elasticity_R6': 0.55, 'l_cheek_elasticity_R7': 0.324, 'l_cheek_elasticity_R8': 0.213, 'l_cheek_elasticity_R9': 0.051, 'l_cheek_elasticity_Q0': 71.0, 'l_cheek_elasticity_Q1': 0.534, 'l_cheek_elasticity_Q2': 0.408, 'l_cheek_elasticity_Q3': 0.126, 'l_cheek_pore': 885.0}\",\n          \"{'l_cheek_moisture': 60.333, 'l_cheek_elasticity_R0': 0.219, 'l_cheek_elasticity_R1': 0.079, 'l_cheek_elasticity_R2': 0.639, 'l_cheek_elasticity_R3': 0.242, 'l_cheek_elasticity_R4': 0.11, 'l_cheek_elasticity_R5': 0.644, 'l_cheek_elasticity_R6': 0.659, 'l_cheek_elasticity_R7': 0.388, 'l_cheek_elasticity_R8': 0.14, 'l_cheek_elasticity_R9': 0.023, 'l_cheek_elasticity_Q0': 43.8, 'l_cheek_elasticity_Q1': 0.567, 'l_cheek_elasticity_Q2': 0.452, 'l_cheek_elasticity_Q3': 0.115, 'l_cheek_pore': 475.0}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12304,\n        \"samples\": [\n          \"0764_02_L.jpg\",\n          \"0627_01_L30.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 317,\n        \"min\": 1,\n        \"max\": 1100,\n        \"num_unique_values\": 965,\n        \"samples\": [\n          998,\n          468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 13,\n        \"max\": 69,\n        \"num_unique_values\": 57,\n        \"samples\": [\n          13,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"2023-09-21\",\n          \"2023-10-05\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sensitive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"device\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 226,\n        \"min\": 360,\n        \"max\": 4896,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          863,\n          2556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 284,\n        \"min\": 480,\n        \"max\": 6528,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          6528,\n          1440\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"angle\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          7,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"facepart\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12304,\n        \"samples\": [\n          \"[613, 1445, 672, 2005]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pigmentation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":160}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}