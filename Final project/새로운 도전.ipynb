{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNOH8b16i2EADnsLBfySQJq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"metadata":{"id":"_yRge1eClXgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"collapsed":true,"id":"jTD6FuDylbI-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from IPython.display import display, Javascript\n","from keras.utils import to_categorical"],"metadata":{"id":"97MKDNVBibez"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))"],"metadata":{"id":"9Cou0VSbidwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    # '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv'에서 데이터를 로드\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.css')\n","\n","    # 문자열로 저장된 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df = df[df['split'] == 'Training']\n","    return preprocess_data(df)\n","\n","# 데이터 전처리\n","# annotations를 처리하여 리스트 형태의 값을 길이로 변환\n","# equipment에서 딕셔너리가 아닌 값은 빈 딕셔너리로 정리\n","def preprocess_data(df):\n","    def process_annotations(anno):\n","        if isinstance(anno, dict):\n","            return {k: len(v) if isinstance(v, list) else v for k, v in anno.items()}\n","        return {}\n","\n","    df['annotations'] = df['annotations'].apply(process_annotations)\n","    df['equipment'] = df['equipment'].apply(lambda x: x if isinstance(x, dict) else {})\n","    return merge_eye_cheek_data(df)\n","\n","# 눈가와 볼 데이터 합치기\n","# facepart 3,4를 34로, 5,6을 56으로 통일\n","def merge_eye_cheek_data(df):\n","    df.loc[df['images'].apply(lambda x: x['facepart'] in [3, 4]), 'images'] = df['images'].apply(lambda x: {**x, 'facepart': 34} if x['facepart'] in [3, 4] else x)\n","    df.loc[df['images'].apply(lambda x: x['facepart'] in [5, 6]), 'images'] = df['images'].apply(lambda x: {**x, 'facepart': 56} if x['facepart'] in [5, 6] else x)\n","    return df"],"metadata":{"id":"gedLB8mdijGF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 증강 함수\n","# 이미지에 상하 전환, 대비, 회전 적용\n","def augment_data(image):\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","    return image\n","\n","# lr_poly 함수 정의\n","def lr_poly(initial_lr, iter, max_iter, power):\n","    return initial_lr * ((1 - float(iter) / max_iter) ** power)\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.resnet50.preprocess_input(img)\n","    return img\n","\n","# 데이터 제너레이터 생성 함수\n","def create_data_generator(datagen, X, y, directory):\n","    df = pd.DataFrame({'filename': X})\n","    for col in y.columns:\n","        df[col] = y[col]\n","\n","    return datagen.flow_from_dataframe(\n","        dataframe=df,\n","        directory=directory,\n","        x_col='filename',\n","        y_col=y.columns.tolist(),\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='raw'\n","    )"],"metadata":{"id":"-1QnuKXBrInp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet50 모델 생성\n","# 분류와 회귀를 위한 출력층 추가\n","def create_model(output_dims):\n","    # ImageNet 가중치로 초기화된 ResNet50 모델 생성\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    outputs = []\n","    for name, dim in output_dims.items():\n","        if dim == 1:  # 회귀 출력\n","            outputs.append(Dense(1, name=name)(x))\n","        else:  # 분류 출력\n","            outputs.append(Dense(dim, activation='softmax', name=name)(x))\n","    return Model(inputs=base_model.input, outputs=outputs)"],"metadata":{"id":"bEGXXb71rGwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습\n","def train_model(model, train_data, val_data, output_dims, facepart, model_type, epochs=100, batch_size=32):\n","    # 하이퍼파라미터 설정\n","    initial_lr = 1e-3\n","    power = 0.9\n","    optimizer = Adam(learning_rate=initial_lr)\n","\n","    # 손실 함수와 평가 지표 설정\n","    losses = {}\n","    metrics = {}\n","    for name, dim in output_dims.items():\n","        if dim == 1:  # 회귀\n","            losses[name] = 'mean_squared_error'\n","            metrics[name] = 'mae'\n","        else:  # 분류\n","            losses[name] = 'sparse_categorical_crossentropy'\n","            metrics[name] = 'accuracy'\n","\n","    model.compile(optimizer=optimizer, loss=losses, metrics=metrics)\n","\n","    # 체크포인트 설정 (10 에폭마다 저장)\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{model_type}_checkpoint_{{epoch:02d}}.h5',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='loss',\n","        mode='min',\n","        save_freq=10)\n","\n","    # 모델 학습\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        batch_size=batch_size,\n","        callbacks=[\n","            tf.keras.callbacks.LearningRateScheduler(lambda epoch: lr_poly(initial_lr, epoch, epochs, power)),\n","            checkpoint_callback,\n","            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True)\n","        ])\n","\n","    # 최종 모델 저장\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{model_type}_final_model.h5')\n","    return history"],"metadata":{"id":"lFAJyhClrFe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 성능 시각화 함수\n","# 학습 과정의 손실과 성능을 그래프 시각화\n","def plot_performance(history, output_dims, facepart, model_type):\n","    n_metrics = len(output_dims)\n","    fig, axes = plt.subplots(n_metrics, 2, figsize=(15, 5*n_metrics))\n","\n","    for i, (name, dim) in enumerate(output_dims.items()):\n","        # Loss plot\n","        axes[i, 0].plot(history.history[f'{name}_loss'], label='Train Loss')\n","        axes[i, 0].plot(history.history[f'val_{name}_loss'], label='Validation Loss')\n","        axes[i, 0].set_title(f'{name} Loss')\n","        axes[i, 0].set_xlabel('Epoch')\n","        axes[i, 0].set_ylabel('Loss')\n","        axes[i, 0].legend()\n","\n","        # Metric plot\n","        metric = 'accuracy' if dim > 1 else 'mae'\n","        axes[i, 1].plot(history.history[f'{name}_{metric}'], label=f'Train {metric.upper()}')\n","        axes[i, 1].plot(history.history[f'val_{name}_{metric}'], label=f'Validation {metric.upper()}')\n","        axes[i, 1].set_title(f'{name} {metric.upper()}')\n","        axes[i, 1].set_xlabel('Epoch')\n","        axes[i, 1].set_ylabel(metric.upper())\n","        axes[i, 1].legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{model_type}_performance.png')\n","    plt.close()"],"metadata":{"id":"RFdCXY5qrCtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 각 facepart에 대해 데이터를 준비하고 모델을 훈련\n","# 분류와 회귀 모델을 별도로 생성하고 훈련\n","# facepart별 모델 훈련\n","def train_facepart_models(facepart):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    # facepart에 따른 데이터 필터링\n","    if facepart in [34, 56]:\n","        facepart_df = df[df['images'].apply(lambda x: x['facepart'] in ([3, 4] if facepart == 34 else [5, 6]))]\n","    else:\n","        facepart_df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","    # bbox 유효성 검사 및 필터링\n","    def valid_bbox(bbox):\n","        if bbox is None:\n","            return False\n","        if isinstance(bbox, list) and len(bbox) == 4:\n","            if bbox == ['None', 'None', 'None', 'None']:\n","                return False\n","            return all(isinstance(b, int) and b > 0 for b in bbox)\n","        return False\n","\n","    facepart_df = facepart_df[facepart_df['images'].apply(lambda x: valid_bbox(x.get('bbox')))]\n","\n","    # 이미지 경로 설정\n","    image_directory = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터' if facepart == 0 else f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","    X = facepart_df['info'].apply(lambda x: os.path.join(image_directory, x['filename'] if facepart == 0 else f\"{x['filename'].split('.')[0]}_{facepart}.jpg\"))\n","\n","    # annotations 및 equipment 데이터 처리\n","    anno_columns = set().union(*facepart_df['annotations'])\n","    equip_columns = set().union(*facepart_df['equipment'])\n","\n","    y_class = pd.DataFrame()\n","    y_reg = pd.DataFrame()\n","    output_dims_class = {}\n","    output_dims_reg = {}\n","\n","    # 분류 데이터 준비\n","    for col in anno_columns:\n","        y_class[col] = facepart_df['annotations'].apply(lambda x: x.get(col, None))\n","        output_dims_class[col] = len(set(y_class[col].dropna())) if len(set(y_class[col].dropna())) > 1 else 1\n","\n","    # 회귀 데이터 준비\n","    for col in equip_columns:\n","        y_reg[col] = facepart_df['equipment'].apply(lambda x: x.get(col, None))\n","        output_dims_reg[col] = 1  # 회귀\n","\n","    # facepart 0에 대한 특별 처리\n","    if facepart == 0:\n","        y_class['skin_type'] = facepart_df['info'].apply(lambda x: x['skin_type'])\n","        y_class['sensitive'] = facepart_df['info'].apply(lambda x: x['sensitive'])\n","        output_dims_class['skin_type'] = len(set(y_class['skin_type'].dropna()))\n","        output_dims_class['sensitive'] = len(set(y_class['sensitive'].dropna()))\n","        y_class['acne_count'] = facepart_df['annotations'].apply(lambda x: len(x.get('acne', [])))\n","        output_dims_class['acne_count'] = 1  # 회귀\n","\n","    # 분류 모델 학습\n","    if not y_class.empty:\n","        print(f\"Starting classification training for facepart {facepart}\")\n","        X_train, X_val, y_train_class, y_val_class = train_test_split(X, y_class, test_size=0.1, random_state=42)\n","\n","        train_datagen = ImageDataGenerator(preprocessing_function=augment_data)\n","        val_datagen = ImageDataGenerator(preprocessing_function=load_and_preprocess_image)\n","\n","        train_generator_class = create_data_generator(train_datagen, X_train, y_train_class, X_train.iloc[0].rsplit('/', 1)[0])\n","        val_generator_class = create_data_generator(val_datagen, X_val, y_val_class, X_val.iloc[0].rsplit('/', 1)[0])\n","\n","        model_class = create_model(output_dims_class)\n","        history_class = train_model(model_class, train_generator_class, val_generator_class, output_dims_class, facepart, 'classification')\n","        plot_performance(history_class, output_dims_class, facepart, 'classification')\n","\n","    # 회귀 모델 학습\n","    if not y_reg.empty and not all(y_reg.isnull().all()):\n","        print(f\"Starting regression training for facepart {facepart}\")\n","        X_train, X_val, y_train_reg, y_val_reg = train_test_split(X, y_reg, test_size=0.1, random_state=42)\n","\n","        train_generator_reg = create_data_generator(train_datagen, X_train, y_train_reg, X_train.iloc[0].rsplit('/', 1)[0])\n","        val_generator_reg = create_data_generator(val_datagen, X_val, y_val_reg, X_val.iloc[0].rsplit('/', 1)[0])\n","\n","        model_reg = create_model(output_dims_reg)\n","        history_reg = train_model(model_reg, train_generator_reg, val_generator_reg, output_dims_reg, facepart, 'regression')\n","        plot_performance(history_reg, output_dims_reg, facepart, 'regression')"],"metadata":{"id":"c8kwvW05rBI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메인 실행\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 34,56, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = [0, 1, 2]\n","    elif user_input == '2':\n","        facepart_range = [34, 56]\n","    elif user_input == '3':\n","        facepart_range = [7, 8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","\n","    for facepart in facepart_range:\n","        train_facepart_models(facepart)"],"metadata":{"id":"kGMrCITdq-nA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 로드 및 전처리:\n","    - load_and_preprocess_data() 함수:\n","        - '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv'에서 데이터를 로드합니다.\n","        - 문자열로 저장된 딕셔너리를 실제 딕셔너리로 변환합니다.\n","        - Training 데이터만 선택합니다.\n","    - preprocess_data() 함수:\n","        - annotations를 처리하여 리스트 형태의 값을 길이로 변환합니다.\n","        - equipment 데이터를 정리합니다.\n","    - merge_eye_cheek_data() 함수:\n","        - facepart 3,4를 34로, 5,6을 56으로 합칩니다.\n","\n","\n","- 데이터 증강 및 전처리:\n","    - 이미지에 대해 상하 반전, 대비 조정, 회전을 적용하는 augment_data 함수를 정의합니다.\n","    - 이미지를 로드하고 전처리하는 load_and_preprocess_image 함수를 정의합니다.\n","\n","\n","- 데이터 제너레이터 생성:\n","    - create_data_generator 함수를 사용하여 Keras의 ImageDataGenerator를 생성합니다.\n","\n","\n","- facepart별 모델 훈련:\n","    - train_facepart_models 함수에서 각 facepart에 대한 모델을 훈련합니다.\n","    - annotations에 대한 분류 모델과 equipment에 대한 회귀 모델을 생성합니다.\n","    - facepart 0의 경우, info 컬럼의 'skin_type'과 'sensitive'에 대한 추가 분류 모델을 생성합니다.\n","\n","\n","- 모델 훈련:\n","    - train_model 함수에서 실제 모델 훈련이 이루어집니다.\n","    - 학습률 스케줄링, 체크포인트 저장, 조기 종료 등의 콜백을 사용합니다.\n","    - 모델은 '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/' 경로에 저장됩니다.\n","\n","\n","- 성능 시각화:\n","    - plot_performance 함수에서 훈련 및 검증 손실, 정확도 또는 MAE를 시각화합니다.\n","    - 시각화 결과는 '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/' 경로에 저장됩니다.\n","\n","\n","- 메인 실행:\n","    - 사용자 입력에 따라 처리할 facepart 범위를 선택합니다.\n","    - 선택된 facepart에 대해 train_facepart_models 함수를 실행합니다."],"metadata":{"id":"EwyHP3jxj-k6"}}]}