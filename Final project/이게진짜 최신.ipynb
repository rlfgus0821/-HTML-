{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOCPqG7jvTcyAxWAk+d0D3Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4Xj-wkqkxZ8w"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"PoPfoYO5xeCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os"],"metadata":{"id":"6IZ_wUx1xhIV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))\n","\n","# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    # '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv'에서 데이터를 로드\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv')\n","\n","    # 문자열로 저장된 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df = df[df['split'] == 'Training']\n","    return preprocess_data(df)\n","\n","# 데이터 전처리\n","# annotations를 처리하여 리스트 형태의 값을 길이로 변환\n","# equipment에서 딕셔너리가 아닌 값은 빈 딕셔너리로 정리\n","def preprocess_data(df):\n","    # anno는 'annotations' 열의 각 값\n","    def process_annotations(anno):\n","        if isinstance(anno, dict):\n","            # 값 v가 list면, len(v) 반환\n","            # 값 v가 list가 아니라면, 값을 그대로 반환\n","            return {k: len(v) if isinstance(v, list) else v for k, v in anno.items()}\n","        # 입력값 anno가 딕셔너리가 아닌 경우, 빈 사전({})을 반환\n","        return {}\n","\n","    # 'annotations' 열의 각 값이 process_annotations 함수에 전달\n","    df['annotations'] = df['annotations'].apply(process_annotations)\n","    # 'equipment'열의 값이 딕셔너리인지 확인\n","    # 만약 값이 딕셔너리면 그 값을 그대로 두고, 그렇지 않으면 {}로 대체\n","    df['equipment'] = df['equipment'].apply(lambda x: x if isinstance(x, dict) else {})\n","    return merge_eye_cheek_data(df)\n","\n","# 눈가와 볼 데이터 합치기\n","# facepart 3,4를 34로, 5,6을 56으로 통일\n","def merge_eye_cheek_data(df):\n","    df.loc[df['images'].apply(lambda x: x['facepart'] in [3, 4]), 'images'] = df['images'].apply(lambda x: {**x, 'facepart': 34} if x['facepart'] in [3, 4] else x)\n","    df.loc[df['images'].apply(lambda x: x['facepart'] in [5, 6]), 'images'] = df['images'].apply(lambda x: {**x, 'facepart': 56} if x['facepart'] in [5, 6] else x)\n","    return df\n","\n","# 오버샘플링 함수\n","def oversample_data(X, y):\n","    ros = RandomOverSampler(random_state=42)\n","    X_resampled, y_resampled = ros.fit_resample(X.to_frame(), y)\n","    return X_resampled.iloc[:, 0], y_resampled\n","\n","# 클래스 가중치 계산 함수\n","def compute_class_weights(y):\n","    classes = np.unique(y)\n","    weights = compute_class_weight('balanced', classes=classes, y=y)\n","    return dict(zip(classes, weights))\n","\n","# 학습률 조정을 위한 콜백 함수\n","def lr_schedule(epoch, lr):\n","    if epoch < 10:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","# 데이터 증강\n","def augment_data(image):\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","    return image\n","\n","# lr_poly 함수 정의\n","def lr_poly(initial_lr, iter, max_iter, power):\n","    return initial_lr * ((1 - float(iter) / max_iter) ** power)\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.resnet50.preprocess_input(img)\n","    return img\n","\n","# create_data_generator 함수 수정\n","def create_data_generator(X, y, directory, batch_size=32, is_training=True):\n","    def gen():\n","        for i in range(len(X)):\n","            img_path = X.iloc[i]\n","            img = load_and_preprocess_image(img_path)\n","            label = {col: y.iloc[i][col] for col in y.columns}\n","            yield img, label\n","\n","    dataset = tf.data.Dataset.from_generator(\n","        gen,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            {col: tf.TensorSpec(shape=(), dtype=tf.float32) for col in y.columns}\n","        )\n","    )\n","\n","    if is_training:\n","        dataset = dataset.shuffle(buffer_size=len(X))\n","\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","# 검증 데이터 생성기\n","def create_val_data_generator(X, y, directory, batch_size=32):\n","    return create_data_generator(X, y, directory, batch_size, is_training=False)\n","\n","def create_model(output_dims):\n","    # ImageNet 가중치로 초기화된 ResNet50 모델 생성\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    #  ResNet50의 출력을 평탄화\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    outputs = []\n","    for name, dim in output_dims.items():\n","        # 출력 차원이 1인 경우 회귀 출력으로 간주\n","        if dim == 1:  # 회귀 출력\n","            outputs.append(Dense(1, name=name)(x))\n","        # 그렇지 않은 경우 분류 출력으로 간주\n","        else:  # 분류 출력\n","            outputs.append(Dense(dim, activation='softmax', name=name)(x))\n","    return Model(inputs=base_model.input, outputs=outputs)\n","\n","def plot_performance(history, output_dims, facepart, model_type):\n","    n_metrics = len(output_dims)\n","    fig, axes = plt.subplots(n_metrics, 2, figsize=(15, 5*n_metrics))\n","\n","    for i, (name, dim) in enumerate(output_dims.items()):\n","        # Loss plot\n","        axes[i, 0].plot(history.history[f'{name}_loss'], label='Train Loss')\n","        axes[i, 0].plot(history.history[f'val_{name}_loss'], label='Validation Loss')\n","        axes[i, 0].set_title(f'{name} Loss')\n","        axes[i, 0].set_xlabel('Epoch')\n","        axes[i, 0].set_ylabel('Loss')\n","        axes[i, 0].legend()\n","\n","        # Metric plot\n","        metric = 'accuracy' if dim > 1 else 'mae'\n","        axes[i, 1].plot(history.history[f'{name}_{metric}'], label=f'Train {metric.upper()}')\n","        axes[i, 1].plot(history.history[f'val_{name}_{metric}'], label=f'Validation {metric.upper()}')\n","        axes[i, 1].set_title(f'{name} {metric.upper()}')\n","        axes[i, 1].set_xlabel('Epoch')\n","        axes[i, 1].set_ylabel(metric.upper())\n","        axes[i, 1].legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{model_type}_performance.png')\n","    plt.close()\n","\n","# train_model 함수 수정\n","def train_model(model, train_data, val_data, output_dims, facepart, model_type, epochs=100, batch_size=1):\n","    initial_lr = 1e-3\n","    power = 0.9\n","    optimizer = Adam(learning_rate=initial_lr)\n","\n","    losses = {}\n","    metrics = {}\n","    for name, dim in output_dims.items():\n","        if dim == 1:  # 회귀\n","            losses[name] = 'mean_squared_error'\n","            metrics[name] = 'mae'\n","        else:  # 분류\n","            losses[name] = 'sparse_categorical_crossentropy'\n","            metrics[name] = 'accuracy'\n","\n","    model.compile(optimizer=optimizer, loss=losses, metrics=metrics)\n","\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{model_type}_checkpoint_{{epoch:02d}}.keras',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='loss',\n","        mode='min',\n","        save_freq=10)\n","\n","    # 학습률 조정 콜백 추가\n","    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[\n","            tf.keras.callbacks.LearningRateScheduler(lambda epoch: lr_poly(initial_lr, epoch, epochs, power)),\n","            checkpoint_callback,\n","            tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20, restore_best_weights=True),\n","            lr_callback\n","        ])\n","\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{model_type}_final_model.keras')\n","    return history\n","\n","# train_facepart_models 함수 수정\n","def train_facepart_models(facepart, train_classification=True, train_regression=True):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    if facepart in [34, 56]:\n","        facepart_df = df[df['images'].apply(lambda x: x['facepart'] in ([3, 4] if facepart == 34 else [5, 6]))]\n","    else:\n","        facepart_df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","    def valid_bbox(bbox):\n","        if bbox is None:\n","            return False\n","        if isinstance(bbox, list) and len(bbox) == 4:\n","            if bbox == ['None', 'None', 'None', 'None']:\n","                return False\n","            return all(isinstance(b, int) and b > 0 for b in bbox)\n","        return False\n","\n","    facepart_df = facepart_df[facepart_df['images'].apply(lambda x: valid_bbox(x.get('bbox')))]\n","\n","    train_directory = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","    X = facepart_df['info'].apply(lambda x: str(os.path.join(train_directory, f\"{x['filename'].split('.')[0]}_{facepart}.jpg\")))\n","\n","    anno_columns = set().union(*facepart_df['annotations'])\n","    equip_columns = set().union(*facepart_df['equipment'])\n","\n","    y_class = pd.DataFrame()\n","    y_reg = pd.DataFrame()\n","    output_dims_class = {}\n","    output_dims_reg = {}\n","\n","    for col in anno_columns:\n","        y_class[col] = facepart_df['annotations'].apply(lambda x: x.get(col, None))\n","        output_dims_class[col] = len(set(y_class[col].dropna())) if len(set(y_class[col].dropna())) > 1 else 1\n","\n","    for col in equip_columns:\n","        y_reg[col] = facepart_df['equipment'].apply(lambda x: x.get(col, None))\n","        output_dims_reg[col] = 1  # 회귀\n","\n","    if facepart == 0:\n","        y_class['skin_type'] = facepart_df['info'].apply(lambda x: x['skin_type'])\n","        y_class['sensitive'] = facepart_df['info'].apply(lambda x: x['sensitive'])\n","        output_dims_class['skin_type'] = len(set(y_class['skin_type'].dropna()))\n","        output_dims_class['sensitive'] = len(set(y_class['sensitive'].dropna()))\n","        y_class['acne_count'] = facepart_df['annotations'].apply(lambda x: len(x.get('acne', [])))\n","        output_dims_class['acne_count'] = 1  # 회귀\n","\n","    if train_classification and not y_class.empty:\n","        print(f\"Starting classification training for facepart {facepart}\")\n","\n","        X_train, X_val, y_train_class, y_val_class = train_test_split(X, y_class, test_size=0.1, random_state=42)\n","\n","        # 오버샘플링 적용\n","        X_train_resampled, y_train_class_resampled = oversample_data(X_train, y_train_class)\n","\n","        # 클래스 가중치 계산\n","        class_weights = {}\n","        for col in y_train_class_resampled.columns:\n","            if output_dims_class[col] > 1:  # 분류인 경우에만 클래스 가중치 계산\n","                class_weights[col] = compute_class_weights(y_train_class_resampled[col])\n","\n","        train_datagen = ImageDataGenerator(preprocessing_function=augment_data)\n","        val_datagen = ImageDataGenerator(preprocessing_function=load_and_preprocess_image)\n","\n","        train_generator_class = create_data_generator(X_train_resampled, y_train_class_resampled, train_directory)\n","        val_generator_class = create_val_data_generator(X_val, y_val_class, train_directory)\n","\n","        model_class = create_model(output_dims_class)\n","        history_class = train_model(model_class, train_generator_class, val_generator_class, output_dims_class, facepart, 'classification')\n","        plot_performance(history_class, output_dims_class, facepart, 'classification')\n","\n","    if train_regression and not y_reg.empty and not all(y_reg.isnull().all()):\n","        print(f\"Starting regression training for facepart {facepart}\")\n","        X_train, X_val, y_train_reg, y_val_reg = train_test_split(X, y_reg, test_size=0.1, random_state=42)\n","\n","        # 오버샘플링 적용 (회귀에서는 주의가 필요함)\n","        X_train_resampled, y_train_reg_resampled = oversample_data(X_train, y_train_reg)\n","\n","        train_generator_reg = create_data_generator(train_datagen, X_train_resampled, y_train_reg_resampled, train_directory)\n","        val_generator_reg = create_val_data_generator(val_datagen, X_val, y_val_reg, train_directory)\n","\n","        model_reg = create_model(output_dims_reg)\n","        history_reg = train_model(model_reg, train_generator_reg, val_generator_reg, output_dims_reg, facepart, 'regression')\n","        plot_performance(history_reg, output_dims_reg, facepart, 'regression')\n","\n","# 메인 실행\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 34,56, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = [0, 1, 2]\n","    elif user_input == '2':\n","        facepart_range = [34, 56]\n","    elif user_input == '3':\n","        facepart_range = [7, 8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","    train_class = input(\"분류 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    train_reg = input(\"회귀 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    for facepart in facepart_range:\n","        train_facepart_models(facepart, train_classification=train_class, train_regression=train_reg)"],"metadata":{"id":"vS7wtpZJxeEb"},"execution_count":null,"outputs":[]}]}