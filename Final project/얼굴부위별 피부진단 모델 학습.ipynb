{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyNb1lkWbdryIJ3l+n0COnWv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"metadata":{"id":"rzvJXjnb_LSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install efficientnet-pytorch"],"metadata":{"collapsed":true,"id":"OfPvgRUtWjME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from PIL import Image, ImageFile\n","import pandas as pd\n","import pickle\n","import matplotlib.pyplot as plt\n","from efficientnet_pytorch import EfficientNet\n","from IPython.display import display, Javascript\n","from sklearn.model_selection import train_test_split\n","\n","# 잘린 이미지 처리를 위해 설정\n","ImageFile.LOAD_TRUNCATED_IMAGES = True"],"metadata":{"id":"jiF_rm7p_LWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Colab 연결 유지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))"],"metadata":{"id":"JhNo8fGq_LYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 클래스 정의\n","# 이 클래스는 데이터를 불러오고 처리하는 방법을 정의\n","# img_dir은 이미지가 저장된 폴더 경로, df는 데이터프레임, facepart는 얼굴 부위 번호\n","# 데이터셋 클래스 정의\n","class CachedDataset(Dataset):\n","    def __init__(self, img_dir, df, facepart, transform=None, cache_dir='/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'):\n","        self.transform = transform\n","        self.facepart = facepart\n","        os.makedirs(cache_dir, exist_ok=True)\n","        self.cache_file = os.path.join(cache_dir, f'cache_facepart_{facepart}.pkl')\n","\n","        if os.path.exists(self.cache_file):\n","            print(f\"facepart {facepart}의 캐시된 데이터를 불러옵니다...\")\n","            with open(self.cache_file, 'rb') as f:\n","                self.cache = pickle.load(f)\n","        else:\n","            print(f\"facepart {facepart}의 캐시를 생성합니다...\")\n","            self.cache = []\n","            df_facepart = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","            for _, row in df_facepart.iterrows():\n","                try:\n","                    img_name = row['info']['filename']\n","                    if facepart == 0:\n","                        img_path = os.path.join(img_dir, img_name)\n","                    else:\n","                        img_path = os.path.join(img_dir, f\"{os.path.splitext(img_name)[0]}_{facepart}.jpg\")\n","\n","                    if not os.path.exists(img_path):\n","                        print(f\"이미지를 찾을 수 없습니다: {img_path}\")\n","                        continue\n","\n","                    try:\n","                        image = Image.open(img_path).convert('RGB')\n","                    except (IOError, OSError):\n","                        print(f\"손상된 이미지 파일입니다: {img_path}\")\n","                        continue\n","\n","                    if self.transform:\n","                        image = self.transform(image)\n","\n","                    labels = self._prepare_labels(row['annotations'], row['equipment'], row['info'])\n","                    self.cache.append((image, torch.tensor(labels, dtype=torch.float)))\n","                except Exception as e:\n","                    print(f\"데이터 처리 중 오류 발생: {str(e)}\")\n","                    continue\n","\n","            with open(self.cache_file, 'wb') as f:\n","                pickle.dump(self.cache, f)\n","            print(f\"facepart {facepart}의 캐시가 생성되고 저장되었습니다\")\n","\n","    def _prepare_labels(self, annotations, equipment, info):\n","        labels = []\n","        try:\n","            if self.facepart == 0:\n","                labels = [info['skin_type'], info['sensitive']]\n","                if annotations:\n","                    labels.extend(self._process_annotations(annotations))\n","                if equipment:\n","                    labels.extend(list(equipment.values()))\n","            else:\n","                if annotations:\n","                    labels.extend(self._process_annotations(annotations))\n","                if equipment:\n","                    labels.extend(list(equipment.values()))\n","        except Exception as e:\n","            print(f\"레이블 준비 중 오류 발생: {str(e)}\")\n","        return labels\n","\n","    def _process_annotations(self, annotations):\n","        processed = []\n","        for key, value in annotations.items():\n","            if key == 'acne' and isinstance(value, list):\n","                processed.append(len(value))  # 여드름 개수\n","            elif isinstance(value, (int, float)):\n","                processed.append(value)\n","        return processed\n","\n","    def __len__(self):\n","        return len(self.cache)\n","\n","    def __getitem__(self, idx):\n","        return self.cache[idx]"],"metadata":{"id":"c1-9Zyyf_La6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet50 모델 생성 함수\n","def create_resnet_model(num_outputs):\n","    model = models.resnet50(pretrained=True)\n","    num_features = model.fc.in_features\n","    model.fc = nn.Sequential(\n","        nn.Dropout(0.5),\n","        nn.Linear(num_features, num_outputs)\n","    )\n","    return model"],"metadata":{"id":"AMY6WE1S_Ldl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EfficientNet-B0 모델 생성 함수\n","def create_efficientnet_model(num_outputs):\n","    model = EfficientNet.from_pretrained('efficientnet-b0')\n","    num_features = model._fc.in_features\n","    model._fc = nn.Sequential(\n","        nn.Dropout(0.5),\n","        nn.Linear(num_features, num_outputs)\n","    )\n","    return model"],"metadata":{"id":"tfqvcxJU_Lf4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 학습 함수\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, facepart, model_name):\n","    best_val_loss = float('inf')\n","    train_losses = []\n","    val_losses = []\n","    save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, labels in train_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n","\n","        # 검증\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","        val_loss /= len(val_loader)\n","        val_losses.append(val_loss)\n","        print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","        # 최고의 모델 저장\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), os.path.join(save_path, f'best_model_{model_name}_facepart_{facepart}.pth'))\n","            print(f\"facepart {facepart}의 새로운 최고 모델을 저장했습니다\")\n","\n","        # 체크포인트 저장\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': epoch_loss,\n","        }, os.path.join(save_path, f'checkpoint_{model_name}_facepart_{facepart}_epoch_{epoch+1}.pth'))\n","\n","    # 학습 과정 시각화 및 저장\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n","    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(f'Training and Validation Loss for {model_name} Facepart {facepart}')\n","    plt.legend()\n","    plt.xticks(range(0, num_epochs+1, 5))\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(save_path, f'loss_plot_{model_name}_facepart_{facepart}.png'))\n","    plt.close()\n","\n","    return model"],"metadata":{"id":"xeq7pdMFDdb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메인 함수\n","def main():\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    # 문자열 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df_train = df[df['split'] == 'Training']\n","\n","    # 이미지 전처리 정의\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for facepart in range(9):\n","        print(f\"facepart {facepart} 처리 중\")\n","\n","        if facepart == 0:\n","            img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","        else:\n","            img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","        if not os.path.exists(img_dir):\n","            print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","            continue\n","\n","        # 데이터셋 생성\n","        try:\n","            dataset = CachedDataset(\n","                img_dir,\n","                df_train,\n","                facepart,\n","                transform,\n","                cache_dir='/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","            )\n","        except Exception as e:\n","            print(f\"데이터셋 생성 중 오류 발생: {str(e)}\")\n","            continue\n","\n","        # 데이터셋을 train과 validation으로 분할\n","        train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n","\n","        # 데이터 로더 생성\n","        train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\n","        val_loader = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4)\n","\n","        # 모델 생성\n","        num_outputs = len(dataset[0][1])\n","        resnet_model = create_resnet_model(num_outputs).to(device)\n","        efficientnet_model = create_efficientnet_model(num_outputs).to(device)\n","\n","        # 손실 함수와 최적화 알고리즘 정의\n","        criterion = nn.MSELoss()\n","        resnet_optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n","        efficientnet_optimizer = optim.Adam(efficientnet_model.parameters(), lr=0.001)\n","\n","        # ResNet50 모델 학습\n","        try:\n","            resnet_model = train_model(resnet_model, train_loader, val_loader, criterion, resnet_optimizer, num_epochs=30, device=device, facepart=facepart, model_name='resnet50')\n","        except Exception as e:\n","            print(f\"ResNet50 모델 학습 중 오류 발생: {str(e)}\")\n","\n","        # EfficientNet-B0 모델 학습\n","        try:\n","            efficientnet_model = train_model(efficientnet_model, train_loader, val_loader, criterion, efficientnet_optimizer, num_epochs=30, device=device, facepart=facepart, model_name='efficientnet_b0')\n","        except Exception as e:\n","            print(f\"EfficientNet-B0 모델 학습 중 오류 발생: {str(e)}\")\n","\n","        # 최종 모델 저장\n","        save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","        try:\n","            torch.save(resnet_model.state_dict(), os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}.pth'))\n","            torch.save(efficientnet_model.state_dict(), os.path.join(save_path, f'final_model_efficientnet_b0_facepart_{facepart}.pth'))\n","        except Exception as e:\n","            print(f\"모델 저장 중 오류 발생: {str(e)}\")"],"metadata":{"id":"QSqh8813_Llh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    keep_alive()  # 연결 유지 함수 실행\n","    main()"],"metadata":{"id":"EVv-FU9V_Lnk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["위 코드는 class CachedDatase에서 사용가능한 RAM을 넘어갔다고 오류가 나옵니다."],"metadata":{"id":"nD2P6UcRphhe"}},{"cell_type":"code","source":["import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from PIL import Image\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch.nn as nn\n","import torch.optim as optim\n","from efficientnet_pytorch import EfficientNet\n","import matplotlib.pyplot as plt\n","from IPython.display import display, Javascript"],"metadata":{"id":"5SmWVfqLRYnC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install efficientnet-pytorch"],"metadata":{"id":"m2VuX5FgCvnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","# 이 함수는 Colab 연결을 유지하기 위해 60초마다 연결 버튼을 자동으로 클릭\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))"],"metadata":{"id":"DoLiVhe5pgoo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터프레임의 행을 기준으로 이미지 파일을 찾아 처리\n","class DirectDataset(Dataset):\n","    # 데이터셋 초기화\n","    def __init__(self, img_dir, df, facepart, transform=None):\n","        # 이미지 디렉토리, 데이터프레임, facepart, 그리고 transform 함수(resnset에 맞게 이미지 변환)를 입력\n","        self.img_dir = img_dir\n","        self.df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","        self.transform = transform\n","        self.facepart = facepart\n","        self.valid_indices = []\n","\n","        # 유효한 이미지 파일만 포함, 손상된 파일은 제외\n","        for idx, row in self.df.iterrows():\n","            img_name = row['info']['filename']\n","            if self.facepart == 0:\n","                img_path = os.path.join(self.img_dir, img_name)\n","            else:\n","                img_path = os.path.join(self.img_dir, f\"{os.path.splitext(img_name)[0]}_{self.facepart}.jpg\")\n","\n","            if os.path.exists(img_path):\n","                try:\n","                    with Image.open(img_path) as img:\n","                        img.verify()\n","                    self.valid_indices.append(idx)\n","                except (IOError, OSError):\n","                    print(f\"손상된 이미지 파일입니다: {img_path}\")\n","\n","    # 데이터셋의 길이(유효한 이미지 개수)를 반환\n","    def __len__(self):\n","        return len(self.valid_indices)\n","\n","    # 지정된 facepart의 이미지와 레이블을 반환\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[self.valid_indices[idx]]\n","        img_name = row['info']['filename']\n","\n","        if self.facepart == 0:\n","            img_path = os.path.join(self.img_dir, img_name)\n","        else:\n","            img_path = os.path.join(self.img_dir, f\"{os.path.splitext(img_name)[0]}_{self.facepart}.jpg\")\n","\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        labels = self._prepare_labels(row['annotations'], row['equipment'], row['info'])\n","        return image, torch.tensor(labels, dtype=torch.float)\n","\n","    # annotations, equipment, info의 데이터(레이블) 준비\n","    def _prepare_labels(self, annotations, equipment, info):\n","        labels = []\n","        try:\n","            if self.facepart == 0:\n","                labels = [info['skin_type'], info['sensitive']]\n","                if annotations:\n","                    labels.extend(self._process_annotations(annotations))\n","                if equipment:\n","                    labels.extend(list(equipment.values()))\n","            else:\n","                if annotations:\n","                    labels.extend(self._process_annotations(annotations))\n","                if equipment:\n","                    labels.extend(list(equipment.values()))\n","        except Exception as e:\n","            print(f\"레이블 준비 중 오류 발생: {str(e)}\")\n","        return labels\n","\n","    # annotations 데이터를 처리하여 숫자 형태의 레이블로 변환\n","    def _process_annotations(self, annotations):\n","        processed = []\n","        for key, value in annotations.items():\n","            if key == 'acne' and isinstance(value, list):\n","                processed.append(len(value))  # 여드름 개수\n","            elif isinstance(value, (int, float)):\n","                processed.append(value)\n","        return processed"],"metadata":{"id":"RxiFnioJqBoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet50 모델 생성 함수\n","# 사전 학습된 ResNet50 모델을 로드, 마지막 fully connected 층을 num_outputs에 맞게 수정\n","# dropout 층을 추가하여 과적합을 방지\n","def create_resnet_model(num_outputs):\n","    model = models.resnet50(pretrained=True)\n","    num_features = model.fc.in_features\n","    model.fc = nn.Sequential(\n","        nn.Dropout(0.5),\n","        nn.Linear(num_features, num_outputs)\n","    )\n","    return model\n","\n","# 현재 iteration(현재 모델이 몇 번째 반복을 수행 중인지)에 따라 학습률을 감소\n","# 학습이 진행됨에 따라 학습률을 점진적으로 줄여나가는 역할\n","# 학습 초기에는 큰 학습률로 빠르게 학습하다가, 학습이 진행될수록 작은 학습률로 세밀하게 조정\n","# 모델이 더 안정적으로 수렴하도록 도움\n","def lr_poly(base_lr, iter, max_iter, power):\n","    return base_lr * ((1 - float(iter) / max_iter) ** power)"],"metadata":{"id":"MizTrSiJpgxY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델을 학습, 검증, 체크포인트 저장, 학습 과정 시각화\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, facepart):\n","    best_val_loss = float('inf')\n","    train_losses = []\n","    val_losses = []\n","    save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for i, (images, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # 학습률 조정\n","            lr = lr_poly(1e-3, epoch * len(train_loader) + i, num_epochs * len(train_loader), 0.9)\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr\n","\n","            running_loss += loss.item()\n","\n","        epoch_loss = running_loss / len(train_loader)\n","        train_losses.append(epoch_loss)\n","        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n","\n","        # 검증\n","        model.eval()\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","        val_loss /= len(val_loader)\n","        val_losses.append(val_loss)\n","        print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","        # 최고의 모델 저장\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), os.path.join(save_path, f'best_model_resnet50_facepart_{facepart}.pth'))\n","            print(f\"facepart {facepart}의 새로운 최고 모델을 저장했습니다\")\n","\n","        # 체크포인트 저장\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'loss': epoch_loss,\n","        }, os.path.join(save_path, f'checkpoint_resnet50_facepart_{facepart}_epoch_{epoch+1}.pth'))\n","\n","    # 학습 과정 시각화 및 저장\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n","    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(f'Training and Validation Loss for ResNet50 Facepart {facepart}')\n","    plt.legend()\n","    plt.xticks(range(0, num_epochs+1, 5))\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(save_path, f'loss_plot_resnet50_facepart_{facepart}.png'))\n","    plt.close()\n","\n","    return model"],"metadata":{"id":"n_TRGLbLpgz5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# facepart0~2까지 실행"],"metadata":{"id":"9Vygmxdl_JBO"}},{"cell_type":"code","source":["# 0~2\n","# 메인 함수\n","def main():\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    # 문자열 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df_train = df[df['split'] == 'Training']\n","\n","    # 이미지 전처리 정의\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for facepart in range(0,3):\n","        print(f\"facepart {facepart} 처리 중\")\n","\n","        if facepart == 0:\n","            img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","        else:\n","            img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","        if not os.path.exists(img_dir):\n","            print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","            continue\n","\n","        # 데이터셋 생성\n","        try:\n","            dataset = DirectDataset(img_dir, df_train, facepart, transform)\n","        except Exception as e:\n","            print(f\"데이터셋 생성 중 오류 발생: {str(e)}\")\n","            continue\n","\n","        # bbox 검사\n","        for idx, row in df_train.iterrows():\n","            bbox = row['images']['bbox']\n","            if (bbox == ['None', 'None', 'None', 'None']) or not all(isinstance(b, (int, float)) and b is not None for b in bbox):\n","                print(f\"유효하지 않은 bbox: {bbox}\")\n","\n","        # 데이터셋을 train과 validation으로 분할\n","        train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n","\n","        # 데이터 로더 생성\n","        train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n","        val_loader = DataLoader(val_data, batch_size=16, shuffle=False, num_workers=4)\n","\n","        # 모델 생성\n","        num_outputs = len(dataset[0][1])\n","        model = create_resnet_model(num_outputs).to(device)\n","\n","        # 손실 함수와 최적화 알고리즘 정의\n","        criterion = nn.MSELoss()\n","        optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0005)\n","\n","        # ResNet50 모델 학습\n","        try:\n","            model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device=device, facepart=facepart)\n","        except Exception as e:\n","            print(f\"ResNet50 모델 학습 중 오류 발생: {str(e)}\")\n","\n","        # 최종 모델 저장\n","        save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","        try:\n","            torch.save(model.state_dict(), os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}.pth'))\n","        except Exception as e:\n","            print(f\"모델 저장 중 오류 발생: {str(e)}\")"],"metadata":{"id":"7-FFlpUp-gcx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 실행\n","if __name__ == \"__main__\":\n","    keep_alive()  # 연결 유지 함수 실행\n","    main()"],"metadata":{"id":"q0qCYzxk_E8W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# facepart3~6까지 실행"],"metadata":{"id":"laPohzek_FZR"}},{"cell_type":"code","source":["# 3~6\n","# 메인 함수\n","def main():\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    # 문자열 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df_train = df[df['split'] == 'Training']\n","\n","    # 이미지 전처리 정의\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for facepart in range(3,7):\n","        print(f\"facepart {facepart} 처리 중\")\n","\n","        if facepart == 0:\n","            img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","        else:\n","            img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","        if not os.path.exists(img_dir):\n","            print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","            continue\n","\n","        # 데이터셋 생성\n","        try:\n","            dataset = DirectDataset(img_dir, df_train, facepart, transform)\n","        except Exception as e:\n","            print(f\"데이터셋 생성 중 오류 발생: {str(e)}\")\n","            continue\n","\n","        # bbox 검사\n","        for idx, row in df_train.iterrows():\n","            bbox = row['images']['bbox']\n","            if (bbox == ['None', 'None', 'None', 'None']) or not all(isinstance(b, (int, float)) and b is not None for b in bbox):\n","                print(f\"유효하지 않은 bbox: {bbox}\")\n","\n","        # 데이터셋을 train과 validation으로 분할\n","        train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n","\n","        # 데이터 로더 생성\n","        train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n","        val_loader = DataLoader(val_data, batch_size=16, shuffle=False, num_workers=4)\n","\n","        # 모델 생성\n","        num_outputs = len(dataset[0][1])\n","        model = create_resnet_model(num_outputs).to(device)\n","\n","        # 손실 함수와 최적화 알고리즘 정의\n","        criterion = nn.MSELoss()\n","        optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0005)\n","\n","        # ResNet50 모델 학습\n","        try:\n","            model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device=device, facepart=facepart)\n","        except Exception as e:\n","            print(f\"ResNet50 모델 학습 중 오류 발생: {str(e)}\")\n","\n","        # 최종 모델 저장\n","        save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","        try:\n","            torch.save(model.state_dict(), os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}.pth'))\n","        except Exception as e:\n","            print(f\"모델 저장 중 오류 발생: {str(e)}\")"],"metadata":{"id":"w25zeajG-gTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실행\n","if __name__ == \"__main__\":\n","    keep_alive()  # 연결 유지 함수 실행\n","    main()"],"metadata":{"id":"Q_JHzyFP_B_5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# facepart7~8까지 실행"],"metadata":{"id":"ZVp9iSjZ--26"}},{"cell_type":"code","source":["# 7~8\n","# 메인 함수\n","def main():\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    # 문자열 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df_train = df[df['split'] == 'Training']\n","\n","    # 이미지 전처리 정의\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for facepart in range(7,9):\n","        print(f\"facepart {facepart} 처리 중\")\n","\n","        if facepart == 0:\n","            img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","        else:\n","            img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","        if not os.path.exists(img_dir):\n","            print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","            continue\n","\n","        # 데이터셋 생성\n","        try:\n","            dataset = DirectDataset(img_dir, df_train, facepart, transform)\n","        except Exception as e:\n","            print(f\"데이터셋 생성 중 오류 발생: {str(e)}\")\n","            continue\n","\n","        # bbox 검사\n","        for idx, row in df_train.iterrows():\n","            bbox = row['images']['bbox']\n","            if (bbox == ['None', 'None', 'None', 'None']) or not all(isinstance(b, (int, float)) and b is not None for b in bbox):\n","                print(f\"유효하지 않은 bbox: {bbox}\")\n","\n","        # 데이터셋을 train과 validation으로 분할\n","        train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n","\n","        # 데이터 로더 생성\n","        train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n","        val_loader = DataLoader(val_data, batch_size=16, shuffle=False, num_workers=4)\n","\n","        # 모델 생성\n","        num_outputs = len(dataset[0][1])\n","        model = create_resnet_model(num_outputs).to(device)\n","\n","        # 손실 함수와 최적화 알고리즘 정의\n","        criterion = nn.MSELoss()\n","        optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0005)\n","\n","        # ResNet50 모델 학습\n","        try:\n","            model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device=device, facepart=facepart)\n","        except Exception as e:\n","            print(f\"ResNet50 모델 학습 중 오류 발생: {str(e)}\")\n","\n","        # 최종 모델 저장\n","        save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","        try:\n","            torch.save(model.state_dict(), os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}.pth'))\n","        except Exception as e:\n","            print(f\"모델 저장 중 오류 발생: {str(e)}\")\n"],"metadata":{"id":"PabGgQrN-gIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 실행\n","if __name__ == \"__main__\":\n","    keep_alive()  # 연결 유지 함수 실행\n","    main()"],"metadata":{"id":"za12icwf-f97"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 한번에 facepart0~8까지 실행"],"metadata":{"id":"pVbbbgrV-4C7"}},{"cell_type":"code","source":["# 메인 함수\n","def main():\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    # 문자열 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # Training 데이터만 선택\n","    df_train = df[df['split'] == 'Training']\n","\n","    # 이미지 전처리 정의\n","    transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    for facepart in range(9):\n","        print(f\"facepart {facepart} 처리 중\")\n","\n","        if facepart == 0:\n","            img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","        else:\n","            img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","        if not os.path.exists(img_dir):\n","            print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","            continue\n","\n","        # 데이터셋 생성\n","        try:\n","            dataset = DirectDataset(img_dir, df_train, facepart, transform)\n","        except Exception as e:\n","            print(f\"데이터셋 생성 중 오류 발생: {str(e)}\")\n","            continue\n","\n","        # bbox 검사\n","        for idx, row in df_train.iterrows():\n","            bbox = row['images']['bbox']\n","            if (bbox == ['None', 'None', 'None', 'None']) or not all(isinstance(b, (int, float)) and b is not None for b in bbox):\n","                print(f\"유효하지 않은 bbox: {bbox}\")\n","\n","        # 데이터셋을 train과 validation으로 분할\n","        train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n","\n","        # 데이터 로더 생성\n","        train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n","        val_loader = DataLoader(val_data, batch_size=16, shuffle=False, num_workers=4)\n","\n","        # 모델 생성\n","        num_outputs = len(dataset[0][1])\n","        model = create_resnet_model(num_outputs).to(device)\n","\n","        # 손실 함수와 최적화 알고리즘 정의\n","        criterion = nn.MSELoss()\n","        optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0005)\n","\n","        # ResNet50 모델 학습\n","        try:\n","            model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device=device, facepart=facepart)\n","        except Exception as e:\n","            print(f\"ResNet50 모델 학습 중 오류 발생: {str(e)}\")\n","\n","        # 최종 모델 저장\n","        save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","        try:\n","            torch.save(model.state_dict(), os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}.pth'))\n","        except Exception as e:\n","            print(f\"모델 저장 중 오류 발생: {str(e)}\")\n","\n","if __name__ == \"__main__\":\n","    keep_alive()  # 연결 유지 함수 실행\n","    main()"],"metadata":{"id":"JwsSHYeH9FFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AcrYXk9lphBM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a8Rdg8bQphDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"A_UhDMGDphFa"},"execution_count":null,"outputs":[]}]}