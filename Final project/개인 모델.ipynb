{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOwwsCrIX3mfwYQ/2HlhQ6I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Zypiz31-W-b6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"collapsed":true,"id":"dq_XHKm7XCml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","from collections import Counter\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from IPython.display import display, Javascript"],"metadata":{"id":"v2ip8vyCXHUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))\n","\n","# 데이터 로드 및 전처리 함수\n","def load_and_preprocess_data():\n","    # CSV 파일 로드\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/json to df.csv')\n","\n","    # 문자열로 저장된 딕셔너리를 실제 딕셔너리로 변환\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    # 훈련 데이터만 선택\n","    df = df[df['split'] == 'Training']\n","\n","    # 데이터 전처리\n","    return preprocess_data(df)\n","\n","# 데이터 전처리 함수\n","def preprocess_data(df):\n","    # annotations 처리\n","    def process_annotations(anno):\n","        if isinstance(anno, dict):\n","            # acne의 경우 리스트 길이를 값으로 사용\n","            if 'acne' in anno and isinstance(anno['acne'], list):\n","                anno['acne'] = len(anno['acne'])\n","            return anno\n","        return {}\n","\n","    df['annotations'] = df['annotations'].apply(process_annotations)\n","\n","    # equipment 처리\n","    df['equipment'] = df['equipment'].apply(lambda x: x if isinstance(x, dict) else {})\n","\n","    # NaN 값을 0으로 채움\n","    df = df.fillna(0)\n","\n","    # 눈가와 볼 데이터 합치기\n","    return merge_eye_cheek_data(df)\n","\n","# 눈가와 볼 데이터 합치기 함수\n","def merge_eye_cheek_data(df):\n","    # 눈가(3,4)를 34로, 볼(5,6)을 56으로 통합\n","    df.loc[df['images'].apply(lambda x: x['facepart'] in [3, 4]), 'images'] = df['images'].apply(lambda x: {**x, 'facepart': 34} if x['facepart'] in [3, 4] else x)\n","    df.loc[df['images'].apply(lambda x: x['facepart'] in [5, 6]), 'images'] = df['images'].apply(lambda x: {**x, 'facepart': 56} if x['facepart'] in [5, 6] else x)\n","\n","    # 통합된 데이터 처리\n","    for facepart in [34, 56]:\n","        df_part = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","        # annotations 통합\n","        merged_annotations = {}\n","        for _, row in df_part.iterrows():\n","            for k, v in row['annotations'].items():\n","                if k not in merged_annotations:\n","                    merged_annotations[k] = v\n","                elif v > merged_annotations[k]:\n","                    merged_annotations[k] = v\n","\n","        # equipment 통합\n","        merged_equipment = {}\n","        for _, row in df_part.iterrows():\n","            for k, v in row['equipment'].items():\n","                if k not in merged_equipment:\n","                    merged_equipment[k] = v\n","                elif v > merged_equipment[k]:\n","                    merged_equipment[k] = v\n","\n","        # 통합된 데이터로 업데이트\n","        df.loc[df['images'].apply(lambda x: x['facepart'] == facepart), 'annotations'] = [merged_annotations] * len(df_part)\n","        df.loc[df['images'].apply(lambda x: x['facepart'] == facepart), 'equipment'] = [merged_equipment] * len(df_part)\n","\n","    return df\n","\n","# 오버샘플링 함수\n","def oversample_data(X, y):\n","    ros = RandomOverSampler(random_state=42)\n","    X_resampled, y_resampled = ros.fit_resample(X, y)\n","    return X_resampled, y_resampled\n","\n","# 클래스 가중치 계산 함수\n","def compute_class_weights(y):\n","    classes = np.unique(y)\n","    weights = compute_class_weight('balanced', classes=classes, y=y)\n","    return dict(zip(classes, weights))\n","\n","# 데이터 증강 함수\n","def augment_data(image):\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n","    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n","    return image\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img\n","\n","# 데이터 생성기\n","def create_data_generator(X, y, directory, batch_size=32, is_training=True):\n","    def gen():\n","        for i in range(len(X)):\n","            img_path = X.iloc[i]\n","            if isinstance(img_path, pd.Series):\n","                img_path = img_path.iloc[0]\n","            img = load_and_preprocess_image(img_path)\n","            label = y.iloc[i]\n","            yield img, label\n","\n","    dataset = tf.data.Dataset.from_generator(\n","        gen,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(), dtype=tf.float32)\n","        )\n","    )\n","\n","    if is_training:\n","        dataset = dataset.shuffle(buffer_size=len(X))\n","\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","\n","# 모델 생성 함수\n","def create_model(output_dim):\n","    base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","    x = tf.keras.layers.Dense(256, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(0.4)(x)\n","\n","    if output_dim == 1:  # 회귀\n","        output = tf.keras.layers.Dense(1)(x)\n","    else:  # 분류\n","        output = tf.keras.layers.Dense(output_dim, activation='softmax')(x)\n","\n","    return tf.keras.Model(inputs=base_model.input, outputs=output)\n","\n","# 모델 학습 함수\n","def train_model(model, train_data, val_data, output_dim, facepart, feature_name, model_type, epochs=10, batch_size=32):\n","    initial_lr = 1e-4\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n","\n","    if output_dim == 1:  # 회귀\n","        loss = 'mean_squared_error'\n","        metric = 'mae'\n","    else:  # 분류\n","        loss = 'sparse_categorical_crossentropy'\n","        metric = 'accuracy'\n","\n","    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature_name}_{model_type}_checkpoint_{{epoch:02d}}.keras',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='val_loss',\n","        mode='min',\n","        save_freq='epoch')\n","\n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[checkpoint_callback, reduce_lr, early_stopping]\n","    )\n","\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature_name}_{model_type}_final_model.keras')\n","    return history\n","\n","# 성능 시각화 함수\n","def plot_performance(history, facepart, feature_name, model_type):\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n","\n","    # Loss plot\n","    ax1.plot(history.history['loss'], label='Train Loss')\n","    ax1.plot(history.history['val_loss'], label='Validation Loss')\n","    ax1.set_title(f'{feature_name} Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    # Metric plot\n","    metric = 'accuracy' if model_type == 'classification' else 'mae'\n","    ax2.plot(history.history[metric], label=f'Train {metric.upper()}')\n","    ax2.plot(history.history[f'val_{metric}'], label=f'Validation {metric.upper()}')\n","    ax2.set_title(f'{feature_name} {metric.upper()}')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel(metric.upper())\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature_name}_{model_type}_performance.png')\n","    plt.close()\n","\n","# facepart별 모델 학습 함수\n","def train_facepart_models(facepart, df, train_classification=True, train_regression=True):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    if facepart in [34, 56]:  # 눈가와 볼 통합\n","        facepart_df = df[df['images'].apply(lambda x: x['facepart'] in [3, 4] if facepart == 34 else [5, 6])]\n","    else:\n","        facepart_df = df[df['images'].apply(lambda x: x['facepart'] == facepart)]\n","\n","    print(f\"Number of rows for facepart {facepart}: {len(facepart_df)}\")\n","\n","    if facepart == 0:\n","        train_directory = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","    else:\n","        train_directory = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","    X = facepart_df['info'].apply(lambda x: str(os.path.join(train_directory, x['filename'])))\n","\n","    # 분류 모델 학습\n","    if train_classification:\n","        for feature in facepart_df['annotations'].iloc[0].keys():\n","            y = facepart_df['annotations'].apply(lambda x: x.get(feature, 0))\n","            if isinstance(y.iloc[0], list):  # acne의 경우 리스트 길이를 값으로 사용\n","                y = y.apply(len)\n","\n","            if len(set(y)) > 1:  # 클래스가 2개 이상일 때만 학습\n","                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","                # 오버샘플링\n","                X_train_resampled, y_train_resampled = oversample_data(pd.DataFrame(X_train), pd.DataFrame(y_train))\n","\n","                train_generator = create_data_generator(X_train_resampled, y_train_resampled, train_directory)\n","                val_generator = create_data_generator(X_val, y_val, train_directory, is_training=False)\n","\n","                print(f\"Training classification model for feature: {feature}\")\n","                print(f\"Number of training samples: {len(X_train_resampled)}\")\n","                print(f\"Number of validation samples: {len(X_val)}\")\n","\n","                model = create_model(len(set(y)))\n","                history = train_model(model, train_generator, val_generator, len(set(y)), facepart, feature, 'classification')\n","                plot_performance(history, facepart, feature, 'classification')\n","\n","    # 회귀 모델 학습\n","    if train_regression:\n","        regression_features = [\n","            'moisture', 'elasticity_R2', 'pigmentation_count', 'pore'\n","        ]\n","\n","        for feature in regression_features:\n","            if feature in facepart_df['equipment'].iloc[0]:\n","                y = facepart_df['equipment'].apply(lambda x: x.get(feature, 0))\n","\n","                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","                train_generator = create_data_generator(X_train, y_train, train_directory)\n","                val_generator = create_data_generator(X_val, y_val, train_directory, is_training=False)\n","\n","                print(f\"Training regression model for feature: {feature}\")\n","                print(f\"Number of training samples: {len(X_train)}\")\n","                print(f\"Number of validation samples: {len(X_val)}\")\n","\n","                model = create_model(1)  # 회귀 모델은 출력이 1개\n","                history = train_model(model, train_generator, val_generator, 1, facepart, feature, 'regression')\n","                plot_performance(history, facepart, feature, 'regression')\n","\n","# 메인 함수\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 34,56, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = [0, 1, 2]\n","    elif user_input == '2':\n","        facepart_range = [34, 56]\n","    elif user_input == '3':\n","        facepart_range = [7, 8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","\n","    train_class = input(\"분류 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    train_reg = input(\"회귀 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","\n","    for facepart in facepart_range:\n","        train_facepart_models(facepart, df, train_classification=train_class, train_regression=train_reg)"],"metadata":{"id":"0avVzXhJXCpA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WTftMrCce-do"},"execution_count":null,"outputs":[]}]}