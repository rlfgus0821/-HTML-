{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyN1aML4vK5s5V/JbWgp2yIf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"],"metadata":{"id":"CpNtyOu0PsNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"collapsed":true,"id":"GLnd_476UCgK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HBAXD0APn9Q"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","# 이 함수는 Colab 연결을 유지하기 위해 60초마다 연결 버튼을 자동으로 클릭\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))"],"metadata":{"id":"3IrQuFd5P1y0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이 클래스는 데이터를 불러오고 처리하는 방법을 정의 -> 이미지와 라벨 데이터를 캐시하여 빠른 접근을 가능\n","# img_dir은 이미지가 저장된 폴더 경로, df는 데이터프레임, facepart는 얼굴 부위 번호\n","# 데이터셋 클래스 정의\n","\n","class CachedDataset:\n","    def __init__(self, img_dir, df, facepart, task, cache_dir='/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/cache'):\n","        self.img_dir = img_dir\n","        self.facepart = facepart\n","        self.task = task\n","        os.makedirs(cache_dir, exist_ok=True)\n","        self.cache_file = os.path.join(cache_dir, f'cache_facepart_{facepart}_{task}.npy')\n","\n","        if os.path.exists(self.cache_file):\n","            print(f\"facepart {facepart}의 {task} 캐시된 데이터를 불러옵니다...\")\n","            self.cache = np.load(self.cache_file, allow_pickle=True)\n","        else:\n","            print(f\"facepart {facepart}의 {task} 캐시를 생성합니다...\")\n","            self.cache = self._create_cache(df)\n","            np.save(self.cache_file, self.cache)\n","            print(f\"facepart {facepart}의 {task} 캐시가 생성되고 저장되었습니다\")\n","\n","        self.class_weights = self._compute_class_weights()\n","        self.datagen = ImageDataGenerator(\n","            vertical_flip=True,\n","            rotation_range=20,\n","            brightness_range=[0.8, 1.2],\n","            validation_split=0.1\n","        )\n","\n","    def _create_cache(self, df):\n","        cache = []\n","        df_facepart = df[df['images'].apply(lambda x: x['facepart'] == self.facepart)]\n","\n","        for idx, row in df_facepart.iterrows():\n","            try:\n","                bbox = row['images']['bbox']\n","                if not isinstance(bbox, list) or len(bbox) != 4 or not all(isinstance(b, (int, float)) for b in bbox):\n","                    continue\n","\n","                img_name = row['info']['filename']\n","                if self.facepart == 0:\n","                    img_path = os.path.join(self.img_dir, img_name)\n","                else:\n","                    img_path = os.path.join(self.img_dir, f\"{os.path.splitext(img_name)[0]}_{self.facepart}.jpg\")\n","\n","                if not os.path.exists(img_path):\n","                    continue\n","\n","                labels = self._prepare_labels(row['annotations'], row['equipment'], row['info'])\n","                if labels is not None:\n","                    cache.append((img_path, labels))\n","\n","            except Exception as e:\n","                print(f\"데이터 처리 중 오류 발생: {str(e)}\")\n","                continue\n","\n","        return cache\n","\n","    def _prepare_labels(self, annotations, equipment, info):\n","        labels = []\n","        try:\n","            if self.task == 'classification':\n","                if self.facepart == 0:\n","                    labels = [info['skin_type'], info['sensitive']]\n","                elif annotations:\n","                    labels = list(annotations.values())\n","                labels = [int(label) if isinstance(label, (int, float)) else 0 for label in labels]\n","                labels = np.array(labels)\n","            elif self.task == 'regression':\n","                if equipment:\n","                    labels = list(equipment.values())\n","                labels = [float(label) if isinstance(label, (int, float)) else 0.0 for label in labels]\n","                labels = np.array(labels)\n","\n","            if labels.size == 0:\n","                return None\n","        except Exception as e:\n","            print(f\"레이블 준비 중 오류 발생: {str(e)}\")\n","            return None\n","        return labels\n","\n","    def _compute_class_weights(self):\n","        if self.task == 'classification':\n","            all_labels = np.concatenate([label for _, label in self.cache])\n","            class_weights = compute_class_weight('balanced', classes=np.unique(all_labels), y=all_labels)\n","            return dict(enumerate(class_weights))\n","        return None\n","\n","    def __len__(self):\n","        return len(self.cache)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.cache[idx]\n","        image = load_img(img_path, target_size=(224, 224))\n","        image = img_to_array(image)\n","        image = preprocess_input(image)\n","        return image, label\n","\n","    def get_num_classes(self):\n","        if self.task == 'classification':\n","            all_labels = np.concatenate([label for _, label in self.cache])\n","            return np.max(all_labels) + 1\n","        else:\n","            return self.cache[0][1].shape[0] if len(self.cache) > 0 else 0\n","\n","    def get_generator(self, subset):\n","        while True:\n","            for img_path, label in self.cache:\n","                image = load_img(img_path, target_size=(224, 224))\n","                image = img_to_array(image)\n","                image = preprocess_input(image)\n","                image = self.datagen.random_transform(image)\n","                yield image, label"],"metadata":{"id":"rC9mSjDzP4Lx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ResNet50 모델 생성 함수\n","# 사전 학습된 ResNet50 모델을 로드, 마지막 fully connected 층을 num_outputs에 맞게 수정\n","# dropout 층을 추가하여 과적합을 방지\n","def create_resnet_model(num_outputs, task):\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    x = GlobalAveragePooling2D()(base_model.output)\n","    x = Dropout(0.5)(x)\n","    if task == 'classification':\n","        outputs = Dense(num_outputs, activation='softmax')(x)\n","    else:  # regression\n","        outputs = Dense(num_outputs, activation='linear')(x)\n","    model = Model(inputs=base_model.input, outputs=outputs)\n","    return model\n","\n","# 현재 iteration(현재 모델이 몇 번째 반복을 수행 중인지)에 따라 학습률을 감소\n","# 학습이 진행됨에 따라 학습률을 점진적으로 줄여나가는 역할\n","# 학습 초기에는 큰 학습률로 빠르게 학습하다가, 학습이 진행될수록 작은 학습률로 세밀하게 조정\n","# 모델이 더 안정적으로 수렴하도록 도움\n","def lr_poly(base_lr, iter, max_iter, power):\n","    return base_lr * ((1 - float(iter) / max_iter) ** power)"],"metadata":{"id":"YNqTxeN8P4OE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델을 학습, 검증, 체크포인트 저장, 학습 과정 시각화\n","def train_model(model, train_dataset, val_dataset, num_epochs, facepart, task):\n","    save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model'\n","\n","    def lr_scheduler(epoch, lr):\n","        return lr_poly(1e-3, epoch, num_epochs, 0.9)\n","\n","    callbacks = [\n","        ModelCheckpoint(os.path.join(save_path, f'best_model_resnet50_facepart_{facepart}_{task}.h5'),\n","                        save_best_only=True, monitor='val_loss'),\n","        EarlyStopping(patience=10, restore_best_weights=True),\n","        LearningRateScheduler(lr_scheduler),\n","        ModelCheckpoint(os.path.join(save_path, f'checkpoint_resnet50_facepart_{facepart}_{task}_epoch_{{epoch:02d}}.h5'),\n","                        save_weights_only=True, period=10)\n","    ]\n","\n","    optimizer = Adam(learning_rate=1e-3)\n","    if task == 'classification':\n","        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    else:  # regression\n","        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n","\n","    history = model.fit(\n","        train_dataset.get_generator('training'),\n","        steps_per_epoch=len(train_dataset) // 32,\n","        validation_data=val_dataset.get_generator('validation'),\n","        validation_steps=len(val_dataset) // 32,\n","        epochs=num_epochs,\n","        callbacks=callbacks,\n","        verbose=1,\n","        class_weight=train_dataset.class_weights if task == 'classification' else None\n","    )\n","\n","    # 학습 과정 시각화 및 저장\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['loss'], label='Train Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(f'Loss for ResNet50 Facepart {facepart} {task}')\n","    plt.legend()\n","    plt.xticks(range(0, num_epochs+1, 5))\n","\n","    plt.subplot(1, 2, 2)\n","    metric_key = 'accuracy' if task == 'classification' else 'mae'\n","    plt.plot(history.history[metric_key], label=f'Train {metric_key.capitalize()}')\n","    plt.plot(history.history[f'val_{metric_key}'], label=f'Validation {metric_key.capitalize()}')\n","    plt.xlabel('Epochs')\n","    plt.ylabel(metric_key.capitalize())\n","    plt.title(f'{metric_key.capitalize()} for ResNet50 Facepart {facepart} {task}')\n","    plt.legend()\n","    plt.xticks(range(0, num_epochs+1, 5))\n","\n","    plt.tight_layout()\n","    plt.savefig(os.path.join(save_path, f'plot_resnet50_facepart_{facepart}_{task}.png'))\n","    plt.close()\n","\n","    return model"],"metadata":{"id":"1W-8CA87P4Qc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메인함수\n","def main(facepart_range):\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    df_train = df[df['split'] == 'Training']\n","\n","    for facepart in facepart_range:\n","        for task in ['classification', 'regression']:\n","            if task == 'regression' and facepart in [2, 7]:\n","                continue\n","\n","            print(f\"facepart {facepart} {task} 처리 중\")\n","\n","            if facepart == 0:\n","                img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","            else:\n","                img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","            if not os.path.exists(img_dir):\n","                print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","                continue\n","\n","            try:\n","                dataset = CachedDataset(img_dir, df_train, facepart, task)\n","                if len(dataset) == 0:\n","                    print(f\"facepart {facepart}의 {task} 데이터셋이 비어 있습니다. 다음으로 진행합니다.\")\n","                    continue\n","\n","                # 모델 생성\n","                num_classes = dataset.get_num_classes()\n","                model = create_resnet_model(num_classes, task)\n","\n","                # 데이터 분할\n","                train_size = int(0.9 * len(dataset))\n","                val_size = len(dataset) - train_size\n","                train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=0)\n","\n","                # 모델 학습\n","                model = train_model(model, train_dataset, val_dataset, num_epochs=100,\n","                                    facepart=facepart, task=task)\n","\n","            except Exception as e:\n","                print(f\"처리 중 오류 발생: {str(e)}\")\n","                continue\n","\n","            # 최종 모델 저장\n","            save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","            try:\n","                model.save(os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}_{task}.h5'))\n","            except Exception as e:\n","                print(f\"모델 저장 중 오류 발생: {str(e)}\")"],"metadata":{"id":"8wcw6NfGP4S1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메인 실행\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 3-6, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = range(0, 3)\n","    elif user_input == '2':\n","        facepart_range = range(3, 7)\n","    elif user_input == '3':\n","        facepart_range = range(7, 9)\n","    else:\n","        print(\"잘못된 입력입니다. 프로그램을 종료합니다.\")\n","        exit()\n","\n","    main(facepart_range)"],"metadata":{"id":"rnSKAnm7P4VV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","\n","from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)\n","\n","# 런타임 오류 방지 함수\n","# 이 함수는 Colab 연결을 유지하기 위해 60초마다 연결 버튼을 자동으로 클릭\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))\n","\n","class CachedDataset:\n","    def __init__(self, img_dir, df, facepart, task, cache_dir='/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/cache'):\n","        self.img_dir = img_dir\n","        self.facepart = facepart\n","        self.task = task\n","        os.makedirs(cache_dir, exist_ok=True)\n","        self.cache_file = os.path.join(cache_dir, f'cache_facepart_{facepart}_{task}.npy')\n","\n","        if os.path.exists(self.cache_file):\n","            print(f\"facepart {facepart}의 {task} 캐시된 데이터를 불러옵니다...\")\n","            try:\n","                self.cache = np.load(self.cache_file, allow_pickle=True)\n","            except Exception as e:\n","                print(f\"캐시 파일 로딩 중 오류 발생: {str(e)}\")\n","                print(\"캐시를 새로 생성합니다...\")\n","                self.cache = self._create_cache(df)\n","                np.save(self.cache_file, self.cache)\n","        else:\n","            print(f\"facepart {facepart}의 {task} 캐시를 생성합니다...\")\n","            self.cache = self._create_cache(df)\n","            np.save(self.cache_file, self.cache)\n","            print(f\"facepart {facepart}의 {task} 캐시가 생성되고 저장되었습니다\")\n","\n","        self.class_weights = self._compute_class_weights()\n","        self.datagen = ImageDataGenerator(\n","            vertical_flip=True,\n","            rotation_range=20,\n","            brightness_range=[0.8, 1.2],\n","            validation_split=0.1\n","        )\n","\n","        if self.task == 'classification':\n","            self._balance_classes()\n","\n","    def _create_cache(self, df):\n","        cache = []\n","        df_facepart = df[df['images'].apply(lambda x: x['facepart'] == self.facepart)]\n","\n","        for idx, row in df_facepart.iterrows():\n","            try:\n","                bbox = row['images']['bbox']\n","                if not isinstance(bbox, list) or len(bbox) != 4 or not all(isinstance(b, (int, float)) for b in bbox):\n","                    continue\n","\n","                img_name = row['info']['filename']\n","                if self.facepart == 0:\n","                    img_path = os.path.join(self.img_dir, img_name)\n","                else:\n","                    img_path = os.path.join(self.img_dir, f\"{os.path.splitext(img_name)[0]}_{self.facepart}.jpg\")\n","\n","                if not os.path.exists(img_path):\n","                    continue\n","\n","                labels = self._prepare_labels(row['annotations'], row['equipment'], row['info'])\n","                if labels is not None:\n","                    cache.append((img_path, labels))\n","\n","            except Exception as e:\n","                print(f\"데이터 처리 중 오류 발생: {str(e)}\")\n","                continue\n","\n","        return cache\n","\n","    def _prepare_labels(self, annotations, equipment, info):\n","        labels = []\n","        try:\n","            if self.task == 'classification':\n","                if self.facepart == 0:\n","                    labels = [info['skin_type'], info['sensitive']]\n","                elif annotations:\n","                    labels = list(annotations.values())\n","                labels = [int(label) if isinstance(label, (int, float)) else 0 for label in labels]\n","                labels = np.array(labels)\n","            elif self.task == 'regression':\n","                if equipment:\n","                    labels = list(equipment.values())\n","                labels = [float(label) if isinstance(label, (int, float)) else 0.0 for label in labels]\n","                labels = np.array(labels)\n","\n","            if labels.size == 0:\n","                return None\n","        except Exception as e:\n","            print(f\"레이블 준비 중 오류 발생: {str(e)}\")\n","            return None\n","        return labels\n","\n","    def _compute_class_weights(self):\n","        if self.task == 'classification':\n","            all_labels = np.concatenate([label for _, label in self.cache])\n","            class_weights = compute_class_weight('balanced', classes=np.unique(all_labels), y=all_labels)\n","            return dict(enumerate(class_weights))\n","        return None\n","\n","    def _balance_classes(self):\n","        if self.task == 'classification':\n","            X = np.array([img_path for img_path, _ in self.cache])\n","            y = np.array([label for _, label in self.cache])\n","\n","            ros = RandomOverSampler(random_state=42)\n","            X_resampled, y_resampled = ros.fit_resample(X.reshape(-1, 1), y)\n","\n","            self.cache = [(X_resampled[i][0], y_resampled[i]) for i in range(len(X_resampled))]\n","\n","    def __len__(self):\n","        return len(self.cache)\n","\n","    def __getitem__(self, idx):\n","        img_path, label = self.cache[idx]\n","        image = load_img(img_path, target_size=(224, 224))\n","        image = img_to_array(image)\n","        image = preprocess_input(image)\n","        return image, label\n","\n","    def get_num_classes(self):\n","        if self.task == 'classification':\n","            all_labels = np.concatenate([label for _, label in self.cache])\n","            return np.max(all_labels) + 1\n","        else:\n","            return self.cache[0][1].shape[0] if len(self.cache) > 0 else 0\n","\n","    def get_generator(self, subset):\n","        while True:\n","            for img_path, label in self.cache:\n","                image = load_img(img_path, target_size=(224, 224))\n","                image = img_to_array(image)\n","                image = preprocess_input(image)\n","                image = self.datagen.random_transform(image)\n","                yield image, label\n","\n","# 나머지 함수들은 그대로 유지\n","\n","def main(facepart_range):\n","    base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","\n","    try:\n","        df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","    except FileNotFoundError:\n","        print(\"CSV 파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","        return\n","    except pd.errors.EmptyDataError:\n","        print(\"CSV 파일이 비어있습니다.\")\n","        return\n","    except pd.errors.ParserError:\n","        print(\"CSV 파일 파싱 중 오류가 발생했습니다. 파일 형식을 확인해주세요.\")\n","        return\n","\n","    for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","\n","    df_train = df[df['split'] == 'Training']\n","\n","    for facepart in facepart_range:\n","        for task in ['classification', 'regression']:\n","            if task == 'regression' and facepart in [2, 7]:\n","                continue\n","\n","            print(f\"facepart {facepart} {task} 처리 중\")\n","\n","            if facepart == 0:\n","                img_dir = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","            else:\n","                img_dir = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","\n","            if not os.path.exists(img_dir):\n","                print(f\"이미지 디렉토리를 찾을 수 없습니다: {img_dir}\")\n","                continue\n","\n","            try:\n","                dataset = CachedDataset(img_dir, df_train, facepart, task)\n","                if len(dataset) == 0:\n","                    print(f\"facepart {facepart}의 {task} 데이터셋이 비어 있습니다. 다음으로 진행합니다.\")\n","                    continue\n","\n","                # 모델 생성\n","                num_classes = dataset.get_num_classes()\n","                model = create_resnet_model(num_classes, task)\n","\n","                # 데이터 분할\n","                train_size = int(0.9 * len(dataset))\n","                val_size = len(dataset) - train_size\n","                train_dataset, val_dataset = train_test_split(dataset, test_size=0.1, random_state=0)\n","\n","                # 모델 학습\n","                model = train_model(model, train_dataset, val_dataset, num_epochs=100,\n","                                    facepart=facepart, task=task)\n","            except Exception as e:\n","                print(f\"처리 중 오류 발생: {str(e)}\")\n","                continue\n","\n","            # 최종 모델 저장\n","            save_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단'\n","            try:\n","                model.save(os.path.join(save_path, f'final_model_resnet50_facepart_{facepart}_{task}.h5'))\n","            except Exception as e:\n","                print(f\"모델 저장 중 오류 발생: {str(e)}\")\n","\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (1: 0-2, 2: 3-6, 3: 7-8): \")\n","    if user_input == '1':\n","        facepart_range = range(0, 3)\n","    elif user_input == '2':\n","        facepart_range = range(3, 7)\n","    elif user_input == '3':\n","        facepart_range = range(7, 9)\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","\n","    main(facepart_range)"],"metadata":{"id":"Y3Xcd48rfPfW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[954]['annotations']"],"metadata":{"id":"DkQM7KY_nxkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터'\n","df = pd.read_csv(os.path.join(base_path, 'json to df.csv'))\n","for col in ['info', 'images', 'annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","# 'acne' 키의 값이 0이 아닌 행 필터링\n","filtered_df = df[df['annotations'].apply(lambda x: x.get('acne', 0) != 0)]\n","\n","print(filtered_df)"],"metadata":{"id":"NoO3z4qDnYSd"},"execution_count":null,"outputs":[]}]}