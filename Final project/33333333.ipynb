{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMWsu6zcxBAFdnrNrzgOG02"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nWWFtCb942Qy"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive', force_remount=True)"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import RandomOverSampler\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","from IPython.display import display, Javascript"],"metadata":{"id":"bYuA0_uU5Y-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 런타임 오류 방지 함수\n","def keep_alive():\n","    display(Javascript('''\n","        function ClickConnect(){\n","            console.log(\"클릭 연결 버튼\");\n","            document.querySelector(\"colab-connect-button\").click()\n","        }\n","        setInterval(ClickConnect, 60000)\n","    '''))"],"metadata":{"id":"BTDWX4CA5ZAv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/source_type.csv')\n","    for col in ['annotations', 'equipment','bbox']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","    return df\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img"],"metadata":{"id":"Q7OOYlBu5ZDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 생성기\n","def create_data_generator(X, y, batch_size=32, is_training=True):\n","    def gen():\n","        for i in range(len(X)):\n","            img_path = X.iloc[i]\n","            if os.path.exists(img_path):  # 파일 존재 여부 확인\n","                img = load_and_preprocess_image(img_path)\n","                label = y.iloc[i]\n","                yield img, label\n","            else:\n","                print(f\"Skipping missing file: {img_path}\")  # 누락된 파일 정보 출력\n","\n","    dataset = tf.data.Dataset.from_generator(\n","        gen,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(), dtype=tf.float32)\n","        )\n","    )\n","\n","    if is_training:\n","        dataset = dataset.shuffle(buffer_size=len(X))\n","\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset"],"metadata":{"id":"RGkprmCU5ZFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 검증 데이터 생성기\n","def create_val_data_generator(X, y, directory, batch_size=32):\n","    return create_data_generator(X, y, directory, batch_size, is_training=False)"],"metadata":{"id":"glBqAc9qIMNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 생성 함수\n","def create_model(output_dim, model_type):\n","    base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","    x_gap = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n","    x_gmp = tf.keras.layers.GlobalMaxPooling2D()(base_model.output)\n","    x = tf.keras.layers.Concatenate()([x_gap, x_gmp])\n","    x = tf.keras.layers.Dense(256, activation='relu')(x)\n","    x = tf.keras.layers.Dropout(0.4)(x)\n","\n","    if model_type == 'classification':\n","        output = tf.keras.layers.Dense(output_dim, activation='softmax')(x)\n","    else:  # regression\n","        output = tf.keras.layers.Dense(1)(x)\n","\n","    return tf.keras.Model(inputs=base_model.input, outputs=output)"],"metadata":{"id":"kwPLdGwn5ZHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 성능 시각화 함수\n","def plot_performance(history, metric_name, facepart, feature, model_type):\n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n","\n","    # Loss plot\n","    ax1.plot(history.history['loss'], label='Train Loss')\n","    ax1.plot(history.history['val_loss'], label='Validation Loss')\n","    ax1.set_title(f'{feature} Loss')\n","    ax1.set_xlabel('Epoch')\n","    ax1.set_ylabel('Loss')\n","    ax1.legend()\n","\n","    # Metric plot\n","    ax2.plot(history.history[metric_name], label=f'Train {metric_name.upper()}')\n","    ax2.plot(history.history[f'val_{metric_name}'], label=f'Validation {metric_name.upper()}')\n","    ax2.set_title(f'{feature} {metric_name.upper()}')\n","    ax2.set_xlabel('Epoch')\n","    ax2.set_ylabel(metric_name.upper())\n","    ax2.legend()\n","\n","    plt.tight_layout()\n","    plt.savefig(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_performance.png')\n","    plt.close()"],"metadata":{"id":"m1i_Midz5ZJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 훈련 함수\n","def train_model(model, train_data, val_data, facepart, feature, model_type, epochs=25, batch_size=8):\n","    initial_lr = 1e-4\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n","\n","    if model_type == 'regression':\n","        loss = 'mean_squared_error'\n","        metrics = ['mae']\n","    else:  # classification\n","        loss = 'sparse_categorical_crossentropy'\n","        metrics = ['accuracy']\n","\n","    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","        filepath=f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_checkpoint_{{epoch:02d}}.keras',\n","        save_best_only=True,\n","        save_weights_only=False,\n","        monitor='val_loss',\n","        mode='min',\n","        save_freq=10)\n","\n","    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n","\n","    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        verbose=1,\n","        callbacks=[checkpoint_callback, reduce_lr, early_stopping]\n","    )\n","\n","    model.save(f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_{model_type}_final_model.keras')\n","    return history"],"metadata":{"id":"eYUxLTZL6Koc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이미지 경로 가져오기 함수(분류)\n","def get_image_path_classification(row, feature):\n","    facepart = row['facepart']\n","    filename = row['filename'].split('.')[0]\n","    class_value = row['annotations'][feature]\n","    source_type = row['source_type']\n","\n","    if facepart == 0:\n","        base_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 데이터/Training/01.원천데이터'\n","    else:\n","        facepart_names = ['','forehead','glabellus','l_perocular','r_perocular','l_cheek','r_cheek','lip','chin']\n","        base_path = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/classified_cropped/{facepart_names[facepart]}/{feature}/{source_type}/{class_value}'\n","\n","    return str(os.path.join(base_path, f\"{filename}_{facepart}.jpg\"))\n","\n","# 이미지 경로 가져오기 함수(회귀)\n","def get_image_path(row, feature):\n","    facepart = row['facepart']\n","    filename = row['filename'].split('.')[0]\n","    source_type = row['source_type']\n","\n","    if facepart == 0:\n","        base_path = '/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/facepart0_resized'\n","        return f\"{base_path}/{row['filename']}\"\n","    else:\n","        facepart_names = ['','forehead','glabellus','l_perocular','r_perocular','l_cheek','r_cheek','lip','chin']\n","        base_path = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","        return f\"{base_path}/{filename}_{facepart}.jpg\"\n","\n","# bbox 유효성 검증 함수\n","def valid_bbox(bbox):\n","    if bbox is None:\n","        return False\n","    if isinstance(bbox, list) and len(bbox) == 4:\n","        if bbox == ['None', 'None', 'None', 'None']:\n","            return False\n","        return all(isinstance(b, int) and b >= 0 for b in bbox)\n","    return False"],"metadata":{"id":"eb10nBVX6Ks_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# facepart별 모델 훈련 함수\n","def train_facepart_models(facepart, train_classification=True, train_regression=True):\n","    print(f\"Processing facepart {facepart}\")\n","\n","    facepart_df = df[df['facepart'] == facepart]\n","    facepart_df = facepart_df[facepart_df['bbox'].apply(valid_bbox)]\n","\n","    if train_classification:\n","        for feature in facepart_df['annotations'].iloc[0].keys():\n","            model_path = f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_classification_final_model.keras'\n","            if os.path.exists(model_path):\n","                print(f\"Skipping classification training for facepart {facepart}, feature {feature}. Model already exists.\")\n","                continue\n","\n","            y = facepart_df['annotations'].apply(lambda x: x.get(feature, None))\n","\n","            if y.nunique() > 1:\n","                print(f\"Starting classification training for facepart {facepart}, feature {feature}\")\n","\n","                # X = facepart_df.apply(lambda row: get_image_path(row, feature), axis=1)\n","\n","                train_data = facepart_df[facepart_df['source_type'] == 'train']\n","                val_data = facepart_df[facepart_df['source_type'] == 'val']\n","\n","                X_train = train_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                y_train = train_data['annotations'].apply(lambda x: x.get(feature, None))\n","                X_val = val_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                y_val = val_data['annotations'].apply(lambda x: x.get(feature, None))\n","\n","                train_generator = create_data_generator(X_train, y_train)\n","                val_generator = create_data_generator(X_val, y_val)\n","\n","                model = create_model(y.nunique(), 'classification')\n","                history = train_model(model, train_generator, val_generator, facepart, feature, 'classification')\n","                plot_performance(history, ['accuracy'], facepart, feature, 'classification')\n","\n","    if train_regression:\n","        regression_features = ['forehead_moisture', 'r_cheek_moisture', 'l_cheek_moisture', 'chin_moisture',\n","                               'chin_elasticity_R2', 'r_cheek_elasticity_R2', 'l_cheek_elasticity_R2',\n","                               'forehead_elasticity_R2', 'pigmentation_count', 'r_cheek_pore', 'l_cheek_pore']\n","\n","        for feature in regression_features:\n","            model_path = f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_regression_final_model.keras'\n","            if os.path.exists(model_path):\n","                print(f\"Skipping regression training for facepart {facepart}, feature {feature}. Model already exists.\")\n","                continue\n","\n","            if feature in facepart_df['equipment'].iloc[0]:\n","                y = facepart_df['equipment'].apply(lambda x: x.get(feature, None))\n","\n","                if not y.isnull().all():\n","                    print(f\"Starting regression training for facepart {facepart}, feature {feature}\")\n","\n","                    train_data = facepart_df[facepart_df['source_type'] == 'train']\n","                    val_data = facepart_df[facepart_df['source_type'] == 'val']\n","\n","                    X_train = train_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                    y_train = train_data['equipment'].apply(lambda x: x.get(feature, None))\n","                    X_val = val_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","                    y_val = val_data['equipment'].apply(lambda x: x.get(feature, None))\n","\n","                    train_generator = create_data_generator(X_train, y_train)\n","                    val_generator = create_data_generator(X_val, y_val)\n","\n","                    model = create_model(1, 'regression')\n","                    history = train_model(model, train_generator, val_generator, facepart, feature, 'regression')\n","                    plot_performance(history, ['mae'], facepart, feature, 'regression')"],"metadata":{"id":"X6nNCskN6Ky1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# facepart0 모델 훈련 함수\n","def train_facepart0_model(df):\n","    print(\"Processing facepart 0\")\n","\n","    facepart0_df = df[df['facepart'] == 0]\n","    facepart0_df = facepart0_df[facepart0_df['bbox'].apply(valid_bbox)]\n","\n","    for feature in ['skin_type', 'sensitive']:\n","        model_path = f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_classification_final_model.keras'\n","        if os.path.exists(model_path):\n","            print(f\"Skipping classification training for facepart {facepart}, feature {feature}. Model already exists.\")\n","            continue\n","        y = facepart0_df[feature]\n","\n","        if y.nunique() > 1:\n","            print(f\"Starting classification training for facepart 0, feature {feature}\")\n","\n","            train_data = facepart0_df[facepart0_df['source_type'] == 'train']\n","            val_data = facepart0_df[facepart0_df['source_type'] == 'val']\n","\n","            X_train = train_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","            y_train = train_data[feature]\n","            X_val = val_data.apply(lambda row: get_image_path(row, feature), axis=1)\n","            y_val = val_data[feature]\n","\n","            train_generator = create_data_generator(X_train, y_train)\n","            val_generator = create_data_generator(X_val, y_val)\n","\n","            model = create_model(y.nunique(), 'classification')\n","            history = train_model(model, train_generator, val_generator, 0, feature, 'classification')\n","            plot_performance(history, 'accuracy', 0, feature, 'classification')"],"metadata":{"id":"5ItmWFSgKVnc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 메인 함수\n","if __name__ == \"__main__\":\n","    keep_alive()\n","    df = load_and_preprocess_data()\n","    user_input = input(\"처리할 facepart 범위를 선택하세요 (0: 0, 1: 1-2, 2: 3-6, 3: 7-8): \")\n","    if user_input == '0':\n","        facepart_range = [0]\n","    elif user_input == '1':\n","        facepart_range = [1, 2]\n","    elif user_input == '2':\n","        facepart_range = [3, 4, 5, 6]\n","    elif user_input == '3':\n","        facepart_range = [0,7,8]\n","    else:\n","        print(\"잘못된 입력입니다.\")\n","        exit()\n","\n","    train_class = input(\"분류 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","    train_reg = input(\"회귀 모델을 학습하시겠습니까? (y/n): \").lower() == 'y'\n","\n","    for facepart in facepart_range:\n","        if facepart == 0:\n","            train_facepart0_model(df)\n","        else:\n","            train_facepart_models(facepart, train_classification=train_class, train_regression=train_reg)"],"metadata":{"id":"8k6lb5eG6K3F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 테스트"],"metadata":{"id":"gG892V52Iag7"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import mean_absolute_error, accuracy_score, classification_report\n","\n","# 데이터 로드 및 전처리 함수\n","def load_and_preprocess_data():\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/source_type.csv')\n","    for col in ['annotations', 'equipment', 'bbox']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","    return df\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img\n","\n","# 이미지 경로 가져오기 함수\n","def get_image_path(row, feature, facepart):\n","    filename = row['filename'].split('.')[0]\n","    facepart_names = ['', 'forehead', 'glabellus', 'perocular', 'perocular', 'cheek', 'cheek', 'lip', 'chin']\n","    if facepart == 0:\n","        base_path = '/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/facepart0_resized'\n","        return os.path.join(base_path, f\"{filename}.jpg\")\n","    else:\n","        base_path = f'/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/Training_cropped/{facepart}'\n","        return os.path.join(base_path, f\"{filename}_{facepart}.jpg\")\n","\n","# 테스트 데이터 생성기\n","def create_test_data_generator(X, y, batch_size=32):\n","    def gen():\n","        for i in range(len(X)):\n","            img_path = X.iloc[i]\n","            if os.path.exists(img_path):\n","                img = load_and_preprocess_image(img_path)\n","                label = y.iloc[i]\n","                yield img, label\n","            else:\n","                print(f\"Skipping missing file: {img_path}\")\n","\n","    dataset = tf.data.Dataset.from_generator(\n","        gen,\n","        output_signature=(\n","            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n","            tf.TensorSpec(shape=(), dtype=tf.float32)\n","        )\n","    )\n","\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","# 회귀 모델 테스트 함수\n","def test_regression_model(facepart, feature):\n","    print(f\"Testing regression model for facepart {facepart}, feature {feature}\")\n","\n","    # 데이터 로드\n","    df = load_and_preprocess_data()\n","    test_df = df[(df['facepart'] == facepart) & (df['source_type'] == 'test')]\n","\n","    # 테스트 데이터 준비\n","    X_test = test_df.apply(lambda row: get_image_path(row, facepart), axis=1)\n","    y_test = test_df['equipment'].apply(lambda x: x.get(feature, None))\n","\n","    # 데이터 생성기 생성\n","    test_generator = create_test_data_generator(X_test, y_test)\n","\n","    # 모델 로드\n","    model_path = f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_regression_final_model.keras'\n","    model = load_model(model_path)\n","\n","    # 예측\n","    predictions = model.predict(test_generator)\n","\n","    # 성능 평가\n","    mae = mean_absolute_error(y_test, predictions)\n","    print(f\"Mean Absolute Error: {mae}\")\n","\n","    return mae, y_test, predictions\n","\n","# 분류 모델 테스트 함수\n","def test_classification_model(facepart, feature):\n","    print(f\"Testing classification model for facepart {facepart}, feature {feature}\")\n","\n","    # 데이터 로드\n","    df = load_and_preprocess_data()\n","    test_df = df[(df['facepart'] == facepart) & (df['source_type'] == 'test')]\n","\n","    # 테스트 데이터 준비\n","    X_test = test_df.apply(lambda row: get_image_path(row, feature, facepart), axis=1)\n","    y_test = test_df['annotations'].apply(lambda x: x.get(feature, None))\n","\n","    # 데이터 생성기 생성\n","    test_generator = create_test_data_generator(X_test, y_test)\n","\n","    # 모델 로드\n","    model_path = f'/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model/facepart_{facepart}_{feature}_classification_final_model.keras'\n","    model = load_model(model_path)\n","\n","    # 예측\n","    predictions = model.predict(test_generator)\n","    predictions = np.argmax(predictions, axis=1)\n","\n","    # 성능 평가\n","    accuracy = accuracy_score(y_test, predictions)\n","    print(f\"Accuracy: {accuracy}\")\n","    print(classification_report(y_test, predictions))\n","\n","    return accuracy, y_test, predictions\n","\n","# 메인 실행 부분\n","if __name__ == \"__main__\":\n","    # 회귀 모델 테스트 (forehead moisture)\n","    # regression_mae, y_true_reg, y_pred_reg = test_regression_model(1, 'forehead_elasticity_R2')\n","\n","    # # 분류 모델 테스트 (glabellus wrinkle)\n","    classification_accuracy, y_true_cls, y_pred_cls = test_classification_model(0, 'sensitive')"],"metadata":{"id":"dhKYdvFTIbpX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 얼굴부위 분류 및 피부진단 테스트"],"metadata":{"id":"Ya_YgjqC6XxD"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"collapsed":true,"id":"jEdzI1sm9q98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from ultralytics import YOLO\n","import tensorflow as tf\n","\n","def resize_image(img, target_size):\n","    h, w = img.shape[:2]\n","    ratio = min(target_size/h, target_size/w)\n","    new_size = (int(w*ratio), int(h*ratio))\n","    resized = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n","\n","    delta_w = target_size - new_size[0]\n","    delta_h = target_size - new_size[1]\n","    top, bottom = delta_h//2, delta_h-(delta_h//2)\n","    left, right = delta_w//2, delta_w-(delta_w//2)\n","\n","    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0,0,0])\n","    return padded, (top, left), ratio\n","\n","def load_skin_models(model_dir):\n","    models = {}\n","    for model_file in os.listdir(model_dir):\n","        if model_file.endswith(\"_final_model.keras\"):\n","            model_path = os.path.join(model_dir, model_file)\n","            model = tf.keras.models.load_model(model_path)\n","            model_name = model_file.split(\"_final_model.keras\")[0]\n","            models[model_name] = model\n","    return models\n","\n","def predict_skin_condition(cropped_img, models):\n","    results = {}\n","    img = cv2.resize(cropped_img, (224, 224))\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    img = np.expand_dims(img, axis=0)\n","\n","    for model_name, model in models.items():\n","        prediction = model.predict(img)\n","        if 'classification' in model_name:\n","            results[model_name] = np.argmax(prediction[0])\n","        else:  # regression\n","            results[model_name] = prediction[0][0]\n","\n","    return results\n","\n","def analyze_face(image_path, yolo_model_path, skin_model_dir, target_size=640):\n","    # Load models\n","    yolo_model = YOLO(yolo_model_path)\n","    skin_models = load_skin_models(skin_model_dir)\n","\n","    # Load and preprocess image\n","    img = cv2.imread(image_path)\n","    resized_img, (pad_top, pad_left), resize_ratio = resize_image(img, target_size)\n","\n","    # Perform YOLO prediction\n","    results = yolo_model(resized_img)\n","\n","    face_analysis = {}\n","\n","    for r in results:\n","        boxes = r.boxes\n","        for box in boxes:\n","            x1, y1, x2, y2 = box.xyxy[0]\n","\n","            # Calculate coordinates in original image\n","            x1 = max(0, int((x1 - pad_left) / resize_ratio))\n","            y1 = max(0, int((y1 - pad_top) / resize_ratio))\n","            x2 = min(img.shape[1], int((x2 - pad_left) / resize_ratio))\n","            y2 = min(img.shape[0], int((y2 - pad_top) / resize_ratio))\n","\n","            # Get class name\n","            class_name = yolo_model.names[int(box.cls)]\n","\n","            # Crop image\n","            if x1 < x2 and y1 < y2:\n","                cropped_img = img[y1:y2, x1:x2]\n","\n","                if cropped_img.size > 0:\n","                    # Predict skin condition\n","                    skin_prediction = predict_skin_condition(cropped_img, skin_models)\n","                    face_analysis[class_name] = skin_prediction\n","                else:\n","                    print(f\"Warning: Empty image generated for {class_name}\")\n","            else:\n","                print(f\"Warning: Invalid bounding box for {class_name}\")\n","\n","    return face_analysis\n","\n","# Test function for a single image\n","def test_single_image(image_path, yolo_model_path, skin_model_dir):\n","    face_analysis = analyze_face(image_path, yolo_model_path, skin_model_dir)\n","    print(\"Face Analysis Results:\")\n","    for part, predictions in face_analysis.items():\n","        print(f\"\\n{part.upper()}:\")\n","        for feature, value in predictions.items():\n","            print(f\"  {feature}: {value}\")\n","\n","# Test function for facepart1 regression models\n","def test_facepart1_regression(image_path, yolo_model_path, skin_model_dir):\n","    face_analysis = analyze_face(image_path, yolo_model_path, skin_model_dir)\n","    print(\"Facepart1 Regression Results:\")\n","    for part, predictions in face_analysis.items():\n","        if part == \"forehead\":  # Assuming facepart1 corresponds to forehead\n","            for feature, value in predictions.items():\n","                if \"regression\" in feature:\n","                    print(f\"  {feature}: {value}\")\n","\n","# Main function\n","if __name__ == \"__main__\":\n","\n","    user_input = input(\"작업을 선택하세요 (1: 모델 훈련, 2: 단일 이미지 테스트, 3: facepart1 회귀 테스트): \")\n","\n","    if user_input == '1':\n","        # Model training code (as before)\n","        ...\n","\n","    elif user_input == '2':\n","        image_path = input(\"테스트할 이미지 경로를 입력하세요: \")\n","        yolo_model_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/YOLOv8/best.pt'\n","        skin_model_dir = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model'\n","        test_single_image(image_path, yolo_model_path, skin_model_dir)\n","\n","    elif user_input == '3':\n","        image_path = input(\"테스트할 이미지 경로를 입력하세요: \")\n","        yolo_model_path = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/YOLOv8/best.pt'\n","        skin_model_dir = '/gdrive/MyDrive/Final project/1_Red/5_분석모델링/피부진단/model'\n","        test_facepart1_regression(image_path, yolo_model_path, skin_model_dir)\n","\n","    else:\n","        print(\"잘못된 입력입니다.\")"],"metadata":{"id":"yFaZs0GPBEmn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# facepart0 데이터 이미지 크기 줄이기 (가로 720을 기준으로 원본 비율)"],"metadata":{"id":"_-AGtf6gmQXa"}},{"cell_type":"code","source":["from PIL import Image, ImageFile\n","import os\n","\n","# 손상된 파일을 처리할 수 있도록 설정\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","# 이미지가 저장된 기본 폴더 경로\n","base_folder_path = '/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/Training/01.원천데이터'\n","\n","# 리사이즈된 이미지를 저장할 기본 폴더 경로 (기존 폴더를 사용할 수도 있음)\n","output_base_folder_path = '/gdrive/MyDrive/Final project/1_Red/4_데이터탐색_전처리/facepart별 피부 이미지/facepart0_resized'\n","\n","# 가로 크기 기준\n","new_width = 720\n","\n","# 출력 폴더가 존재하지 않으면 생성\n","if not os.path.exists(output_base_folder_path):\n","    os.makedirs(output_base_folder_path)\n","\n","# 재귀적으로 폴더 탐색 및 이미지 리사이즈\n","for root, _, files in os.walk(base_folder_path):\n","    for filename in files:\n","        if filename.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n","            # 이미지 경로\n","            img_path = os.path.join(root, filename)\n","            # 출력 폴더 경로\n","            relative_path = os.path.relpath(root, base_folder_path)\n","            output_folder_path = os.path.join(output_base_folder_path, relative_path)\n","\n","            # 출력 폴더가 존재하지 않으면 생성\n","            if not os.path.exists(output_folder_path):\n","                os.makedirs(output_folder_path)\n","\n","            # 출력 경로 설정\n","            output_path = os.path.join(output_folder_path, filename)\n","\n","            # 이미 파일이 존재하면 넘어가기\n","            if os.path.exists(output_path):\n","                print(f'File already exists, skipping: {output_path}')\n","                continue\n","\n","            try:\n","                # 이미지 열기\n","                img = Image.open(img_path)\n","\n","                # 원본 크기\n","                orig_width, orig_height = img.size\n","\n","                # 새로운 높이 계산 (원본 비율 유지)\n","                new_height = int((new_width / orig_width) * orig_height)\n","\n","                # 이미지 리사이즈\n","                resized_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n","\n","                # 리사이즈된 이미지 저장\n","                resized_img.save(output_path)\n","\n","                print(f'Resized and saved: {output_path}')\n","\n","            except (OSError, IOError) as e:\n","                print(f'Error processing file {img_path}: {e}')\n","                continue\n"],"metadata":{"id":"hmejFzceJDrO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터프레임 전처리"],"metadata":{"id":"fVDerkxM3hEE"}},{"cell_type":"code","source":["# 데이터 로드 및 전처리\n","def load_and_preprocess_data():\n","    df = pd.read_csv('/gdrive/MyDrive/Final project/source_type.csv')\n","    for col in ['info','images','annotations', 'equipment']:\n","        df[col] = df[col].apply(lambda x: eval(x) if isinstance(x, str) else x)\n","    return df\n","\n","# 이미지 로드 및 전처리 함수\n","def load_and_preprocess_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, [224, 224])\n","    img = tf.keras.applications.efficientnet.preprocess_input(img)\n","    return img\n","df = load_and_preprocess_data()\n","df.head(3)"],"metadata":{"id":"OBXYSKFFGhrP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df[df['source_type'] == 'val']['id'].unique()"],"metadata":{"id":"lyeGCgCH0gak"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"5kvDIKmoz2Im"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["info_df = df['info'].apply(pd.Series)\n","\n","# images 컬럼을 분리하여 개별 컬럼으로\n","images_df = df['images'].apply(pd.Series)\n","\n","# 원래의 info와 images 컬럼 제거\n","df = df.drop(['info', 'images'], axis=1)\n","\n","# 새로운 컬럼들을 기존 데이터프레임에 병합\n","df = pd.concat([df, info_df, images_df], axis=1)\n","\n","df.head(3)"],"metadata":{"id":"JiaVnwgXHx9P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.to_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/source_type.csv',index=False)"],"metadata":{"id":"25rosKdb2x1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2 = pd.read_csv('/gdrive/MyDrive/Final project/1_Red/3_데이터수집_저장/0_데이터수집폴더/피부 원본 데이터/source_type.csv')"],"metadata":{"id":"y-FssO_d2_f3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.info()"],"metadata":{"id":"_0CsJqCG3nPH"},"execution_count":null,"outputs":[]}]}