{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정 트리 과대적합(Overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과(대)적합(overfitting)\n",
    "\n",
    "- ML에서 학습 데이타를 과하게 학습하는 것  \n",
    "- 학습(training) 데이터에서는 정확하지만 테스트 데이터에서는 성과가 나쁜 현상  \n",
    "- 결정 트리의 과적합\n",
    "    - 나무의 크기가 크거나 가지 수가 많을 때 발생  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 과적합 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `sklearn.datasets.make_classification()` 함수\n",
    "- 분류용 가상 데이터 생성함수\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0,\n",
    "                    n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0,\n",
    "                    hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수\n",
    "- n_samples : 표본 데이터의 수, 디폴트 100\n",
    "- n_features : 독립 변수의 수, 디폴트 20\n",
    "- n_informative : 독립 변수 중 종속 변수와 상관 관계가 있는 성분의 수, 디폴트 2\n",
    "- n_redundant : 독립 변수 중 다른 독립 변수의 선형 조합으로 나타나는 성분의 수, 디폴트 2\n",
    "- n_repeated : 독립 변수 중 단순 중복된 성분의 수, 디폴트 0\n",
    "- n_classes : 종속 변수의 클래스 수, 디폴트 2\n",
    "- n_clusters_per_class : 클래스 당 클러스터의 수, 디폴트 2\n",
    "- weights : 각 클래스에 할당된 표본 수\n",
    "- random_state : 난수 발생 시드\n",
    "    \n",
    "    \n",
    "반환값\n",
    "- 독립 변수 X : (n_samples, n_features) 크기의 배열\n",
    "- 종속 변수 y : (n_samples,) 크기의 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가상 데이터 생성\n",
    "\n",
    "- 피처=2, 클래스=3 인 100개 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가상 데이터 산점도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가상 데이터에 대한 결정트리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고. Classifier의 Decision Boundary를 시각화 하는 함수\n",
    "- 클래스 값을 예측하는 결정 기준을 색상과 경계로 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_boundary(model, X, y):\n",
    "    fig,ax = plt.subplots()\n",
    "    \n",
    "    # 학습 데이타 scatter plot으로 나타내기\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='rainbow', edgecolor='k',\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim_start , xlim_end = ax.get_xlim()\n",
    "    ylim_start , ylim_end = ax.get_ylim()\n",
    "    \n",
    "    # 호출 파라미터로 들어온 training 데이타로 model 학습 . \n",
    "    model.fit(X, y)\n",
    "    # meshgrid 형태인 모든 좌표값으로 예측 수행. \n",
    "    xx, yy = np.meshgrid(np.linspace(xlim_start,xlim_end, num=200),\n",
    "                         np.linspace(ylim_start,ylim_end, num=200))\n",
    "    \n",
    "    # ravel() : 다차원을 1차원으로 품\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    # contourf() 를 이용하여 class boundary 를 visualization 수행. \n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap='rainbow', clim=(y.min(), y.max()), zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 트리 생성에 제약을 주지 않은 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf=6 인 경우 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
