{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve, roc_curve\n",
    "\n",
    "# 이진 분류 모델의 성능지표\n",
    "def get_eval_score(test_y, pred, pred_proba_c1= None):\n",
    "    \n",
    "    # 혼동행렬(오차행렬)\n",
    "    confusion = confusion_matrix(test_y, pred)\n",
    "    # 정밀도(precision)\n",
    "    precision = precision_score(test_y, pred)\n",
    "    # 정확도(accuracy_score)\n",
    "    accuracy = accuracy_score(test_y, pred)\n",
    "    # 재현율(recall)\n",
    "    recall = recall_score(test_y, pred)\n",
    "    # F1 score\n",
    "    f1 = f1_score(test_y, pred)\n",
    "    # G-measure -> 정밀도와 재현율의 기하평균 -> np.sqrt(recall_socre*precision_score)\n",
    "    g = np.sqrt(recall_score(test_y, pred)*precision_score(test_y, pred))\n",
    "\n",
    "    print(f'confusion matrix:\\n{confusion}\\n')\n",
    "    print(f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}',end=' ')\n",
    "    print(f'F1: {f1:.4f}, G: {g:.4f}')\n",
    "    if pred_proba_c1 is not None:\n",
    "        auc = roc_auc_score(test_y, pred_proba_c1)\n",
    "        print(f'auc: {auc:.4f}')\n",
    "\n",
    "def get_eval_score2(test_y, pred, pred_proba = None):\n",
    "    \n",
    "    # 혼동행렬(오차행렬)\n",
    "    confusion = confusion_matrix(test_y, pred)\n",
    "    # 정밀도(precision)\n",
    "    precision = precision_score(test_y, pred, average='macro')\n",
    "    # 정확도(accuracy_score)\n",
    "    accuracy = accuracy_score(test_y, pred)\n",
    "    # 재현율(recall)\n",
    "    recall = recall_score(test_y, pred, average='macro')\n",
    "    # F1 score\n",
    "    f1 = f1_score(test_y, pred, average='macro')\n",
    "    # G-measure -> 정밀도와 재현율의 기하평균 -> np.sqrt(recall_socre*precision_score)\n",
    "    g = np.sqrt(recall * precision)\n",
    "\n",
    "    print(f'confusion matrix:\\n{confusion}\\n')\n",
    "    print(f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, recall: {recall:.4f}',end=' ')\n",
    "    print(f'F1: {f1:.4f}, G: {g:.4f}')\n",
    "    if pred_proba is not None:\n",
    "        auc = roc_auc_score(test_y, pred_proba, average='macro', multi_class='ovo')\n",
    "        print(f'auc: {auc:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류\n",
    "# 결측치 처리\n",
    "def fill_na(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩\n",
    "def encode_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    for ftr in ['Sex','Cabin','Embarked']: \n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(df[ftr])\n",
    "        df[ftr] = encoder.transform(df[ftr])\n",
    "    return df\n",
    "\n",
    "# 원핫인코딩\n",
    "def encode_features2(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    ftrs = ['Sex','Cabin','Embarked']\n",
    "    dummy = pd.get_dummies(df[ftrs], dtype='int')\n",
    "    df.drop(ftrs, axis=1,inplace=True)\n",
    "    df = pd.concat([df, dummy], axis=1)\n",
    "    return df\n",
    "    \n",
    "# 불필요 열 삭제\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 전처리 함수 / 라벨인코딩 적용\n",
    "def preprocessing_features(df):\n",
    "    df = fill_na(df)\n",
    "    df = drop_features(df)\n",
    "    df = encode_features(df)\n",
    "    return df\n",
    "\n",
    "# 전처리 함수 / 원핫인코딩 적용\n",
    "def preprocessing_features2(df):\n",
    "    df = fill_na(df)\n",
    "    df = drop_features(df)\n",
    "    df = encode_features2(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습문제.\n",
    "\n",
    "1. 타이타닉 데이터셋에 대하여 다음의 예측기들을 사용한 softvoting과 hardvoting을 적용하여 학습하고 성능을 평가하시오.\n",
    "\n",
    "- 원핫인코딩으로 진행\n",
    "- KNN: 이웃의 수 =5\n",
    "- 로지스틱회귀\n",
    "- 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(x,y,voting, estimators,n=5):\n",
    "    # 모델 객체 생성 및 데이터 준비\n",
    "    KNN = KNeighborsClassifier(n_neighbors=n)\n",
    "    lr_clf = LogisticRegression(random_state=0)\n",
    "    dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "    train_x, test_x, train_y, test_y = train_test_split(x,y,test_size=0.2, random_state=156)\n",
    "    vo_clf = VotingClassifier(estimators= estimators, voting=voting)\n",
    "    classes = len(np.unique(y))\n",
    "    # 학습 / 예측 / 평가\n",
    "    vo_clf.fit(train_x, train_y)\n",
    "    pred = vo_clf.predict(test_x)\n",
    "    print(f'{voting}')\n",
    "    if classes < 2:\n",
    "        get_eval_score(test_y, pred)\n",
    "    else:\n",
    "        get_eval_score2(test_y, pred)\n",
    "    print()\n",
    "    print('-------------------\\n')\n",
    "    \n",
    "    # 개별 모델 평가\n",
    "    classifiers = [i[1] for i in estimators]\n",
    "    for clf in classifiers:\n",
    "        clf.fit(train_x, train_y)\n",
    "        pred_y = clf.predict(test_x)\n",
    "        if classes < 2:\n",
    "            pred_proba = clf.predict_proba(test_x)[:,1]\n",
    "            print(clf)\n",
    "            get_eval_score(test_y, pred_y, pred_proba)\n",
    "        else:\n",
    "            pred_proba = clf.predict_proba(test_x)\n",
    "            print(clf)\n",
    "            get_eval_score2(test_y, pred_y, pred_proba)\n",
    "        print('-------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 및 전처리, 분리\n",
    "titanic = pd.read_csv('data/titanic/train.csv')\n",
    "titanic_cl= preprocessing_features2(titanic)\n",
    "\n",
    "x = titanic_cl.drop('Survived', axis=1)\n",
    "y = titanic_cl.Survived\n",
    "\n",
    "est = [('LR',lr_clf),('KNN', knn_clf),('DT',dt_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "KNeighborsClassifier()\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 0.9667, precision: 0.9744, recall: 0.9630 F1: 0.9671, G: 0.9686\n",
      "auc: 0.9722\n",
      "\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# voting = 'hard'\n",
    "voting(x,y,voting='hard',estimators=est,n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "KNeighborsClassifier()\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 0.9667, precision: 0.9744, recall: 0.9630 F1: 0.9671, G: 0.9686\n",
      "auc: 0.9722\n",
      "\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# voting = 'soft'\n",
    "voting(x,y,voting='soft',estimators=est, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 붓꽃 데이터셋에 대하여 다음의 예측기들을 사용한 softvoting과 hardvoting을 적용하여 학습하고 성능을 평가하시오.\n",
    "\n",
    "- KNN: 이웃의 수 = 8\n",
    "- 로지스틱회귀\n",
    "- 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "est = [('LR',lr_clf),('KNN', knn_clf),('DT',dt_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "KNeighborsClassifier()\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 0.9667, precision: 0.9744, recall: 0.9630 F1: 0.9671, G: 0.9686\n",
      "auc: 0.9722\n",
      "\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# voting = 'hard'\n",
    "voting(x,y,voting='hard',estimators=est,n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "KNeighborsClassifier()\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 1.0000, precision: 1.0000, recall: 1.0000 F1: 1.0000, G: 1.0000\n",
      "auc: 1.0000\n",
      "\n",
      "-------------------\n",
      "\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "confusion matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 12]]\n",
      "\n",
      "accuracy: 0.9667, precision: 0.9744, recall: 0.9630 F1: 0.9671, G: 0.9686\n",
      "auc: 0.9722\n",
      "\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# voting = 'soft'\n",
    "voting(x,y,voting='soft',estimators=est,n=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
