{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 카운트 벡터화 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텍스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample_01 = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
    "You can see it out your window or on your television. \\\n",
    "You feel it when you go to work, or go to church or pay your taxes.'\n",
    "\n",
    "text_sample_02 = 'You take the blue pill and the story ends.\\\n",
    "You wake in your bed and you believe whatever you want to believe\\\n",
    "You take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Matrix is everywhere its all around us, here even in this room. You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes.',\n",
       " 'You take the blue pill and the story ends.You wake in your bed and you believe whatever you want to believeYou take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "text.append(text_sample_01)\n",
    "text.append(text_sample_02)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer객체 생성 후 fit()으로 단어사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성된 단어사전 확인 :  `vocabulary_` 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 39, 'matrix': 23, 'is': 20, 'everywhere': 12, 'its': 22, 'all': 0, 'around': 2, 'us': 42, 'here': 16, 'even': 11, 'in': 19, 'this': 40, 'room': 31, 'you': 50, 'can': 7, 'see': 32, 'it': 21, 'out': 26, 'your': 51, 'window': 47, 'or': 25, 'on': 24, 'television': 38, 'feel': 13, 'when': 46, 'go': 14, 'to': 41, 'work': 49, 'church': 8, 'pay': 27, 'taxes': 37, 'take': 36, 'blue': 6, 'pill': 28, 'and': 1, 'story': 35, 'ends': 10, 'wake': 43, 'bed': 3, 'believe': 4, 'whatever': 45, 'want': 44, 'believeyou': 5, 'red': 30, 'stay': 34, 'wonderland': 48, 'show': 33, 'how': 18, 'deep': 9, 'rabbit': 29, 'hole': 17, 'goes': 15}\n"
     ]
    }
   ],
   "source": [
    "# word_index와 비슷하나 인덱스 매핑 기준은 알파벳 순서\n",
    "print(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 적용하여 피처벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x52 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 57 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform -> 피처벡터화 -> 중복된 단어를 제외하고 여러 문서를 합쳐 count 벡터화\n",
    "ftr_mat = cnt_vect.transform(text)\n",
    "ftr_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피처 벡터화 후 데이터 유형 및 여러 속성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2,\n",
       "        1, 1, 1, 3, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0,\n",
       "        0, 0, 1, 1, 0, 1, 3, 3],\n",
       "       [0, 4, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 2, 0, 0, 4, 0, 1, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 6, 1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr_mat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 빈도가 높은 5개 피처만 갖도록 카운트 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "크기 (2, 5)\n",
      "단어집합(사전) {'the': 1, 'you': 3, 'your': 4, 'to': 2, 'and': 0}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(max_features=5)\n",
    "cnt_vect.fit(text)\n",
    "ftr_mat = cnt_vect.transform(text)\n",
    "print(type(ftr_mat))\n",
    "print(f'크기', ftr_mat.shape)\n",
    "print(f'단어집합(사전)', cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ngram_range를 적용한 카운트 벡터화\n",
    "\n",
    "- ngram_range=(1,3) : 단어 1개씩 토큰화하고 순서대로 연속된 3개 단어를 묶어서 피처화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ngram_range=(1,3) -> 단어 1개씩, 2개씩, 3개씩 뭉쳐서 표현\n",
    "- \"고양이는 창문을 통해 나가고 싶어합니다.\" -> \n",
    "- (1-gram): \"고양이는\", \"창문을\", \"통해\", \"나가고\", \"싶어합니다.\"\n",
    "- (2-gram): \"고양이는 창문을\", \"창문을 통해\", \"통해 나가고\", \"나가고 싶어합니다.\"\n",
    "- (3-gram): \"고양이는 창문을 통해\", \"창문을 통해 나가고\", \"통해 나가고 싶어합니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "크기 (2, 202)\n",
      "단어집합(사전) {'the': 130, 'matrix': 78, 'is': 67, 'everywhere': 41, 'its': 75, 'all': 0, 'around': 11, 'us': 151, 'here': 52, 'even': 38, 'in': 60, 'this': 141, 'room': 107, 'you': 175, 'can': 26, 'see': 110, 'it': 70, 'out': 91, 'your': 194, 'window': 166, 'or': 84, 'on': 81, 'television': 127, 'feel': 44, 'when': 163, 'go': 47, 'to': 144, 'work': 172, 'church': 29, 'pay': 94, 'taxes': 126, 'the matrix': 133, 'matrix is': 79, 'is everywhere': 68, 'everywhere its': 42, 'its all': 76, 'all around': 1, 'around us': 12, 'us here': 152, 'here even': 53, 'even in': 39, 'in this': 61, 'this room': 142, 'room you': 108, 'you can': 178, 'can see': 27, 'see it': 111, 'it out': 71, 'out your': 92, 'your window': 200, 'window or': 167, 'or on': 87, 'on your': 82, 'your television': 198, 'television you': 128, 'you feel': 180, 'feel it': 45, 'it when': 73, 'when you': 164, 'you go': 182, 'go to': 48, 'to work': 149, 'work or': 173, 'or go': 85, 'to church': 147, 'church or': 30, 'or pay': 89, 'pay your': 95, 'your taxes': 197, 'the matrix is': 134, 'matrix is everywhere': 80, 'is everywhere its': 69, 'everywhere its all': 43, 'its all around': 77, 'all around us': 2, 'around us here': 13, 'us here even': 153, 'here even in': 54, 'even in this': 40, 'in this room': 62, 'this room you': 143, 'room you can': 109, 'you can see': 179, 'can see it': 28, 'see it out': 112, 'it out your': 72, 'out your window': 93, 'your window or': 201, 'window or on': 168, 'or on your': 88, 'on your television': 83, 'your television you': 199, 'television you feel': 129, 'you feel it': 181, 'feel it when': 46, 'it when you': 74, 'when you go': 165, 'you go to': 183, 'go to work': 50, 'to work or': 150, 'work or go': 174, 'or go to': 86, 'go to church': 49, 'to church or': 148, 'church or pay': 31, 'or pay your': 90, 'pay your taxes': 96, 'take': 122, 'blue': 23, 'pill': 97, 'and': 3, 'story': 119, 'ends': 35, 'wake': 154, 'bed': 14, 'believe': 17, 'whatever': 160, 'want': 157, 'believeyou': 20, 'red': 104, 'stay': 116, 'wonderland': 169, 'show': 113, 'how': 57, 'deep': 32, 'rabbit': 101, 'hole': 55, 'goes': 51, 'you take': 188, 'take the': 123, 'the blue': 131, 'blue pill': 24, 'pill and': 98, 'and the': 6, 'the story': 139, 'story ends': 120, 'ends you': 36, 'you wake': 190, 'wake in': 155, 'in your': 65, 'your bed': 195, 'bed and': 15, 'and you': 8, 'you believe': 176, 'believe whatever': 18, 'whatever you': 161, 'you want': 192, 'want to': 158, 'to believeyou': 145, 'believeyou take': 21, 'the red': 137, 'red pill': 105, 'you stay': 186, 'stay in': 117, 'in wonderland': 63, 'wonderland and': 170, 'and show': 4, 'show you': 114, 'you how': 184, 'how deep': 58, 'deep the': 33, 'the rabbit': 135, 'rabbit hole': 102, 'hole goes': 56, 'you take the': 189, 'take the blue': 124, 'the blue pill': 132, 'blue pill and': 25, 'pill and the': 99, 'and the story': 7, 'the story ends': 140, 'story ends you': 121, 'ends you wake': 37, 'you wake in': 191, 'wake in your': 156, 'in your bed': 66, 'your bed and': 196, 'bed and you': 16, 'and you believe': 9, 'you believe whatever': 177, 'believe whatever you': 19, 'whatever you want': 162, 'you want to': 193, 'want to believeyou': 159, 'to believeyou take': 146, 'believeyou take the': 22, 'take the red': 125, 'the red pill': 138, 'red pill and': 106, 'pill and you': 100, 'and you stay': 10, 'you stay in': 187, 'stay in wonderland': 118, 'in wonderland and': 64, 'wonderland and show': 171, 'and show you': 5, 'show you how': 115, 'you how deep': 185, 'how deep the': 59, 'deep the rabbit': 34, 'the rabbit hole': 136, 'rabbit hole goes': 103}\n"
     ]
    }
   ],
   "source": [
    "cnt_vect = CountVectorizer(ngram_range=(1,3))\n",
    "cnt_vect.fit(text)\n",
    "ftr_mat = cnt_vect.transform(text)\n",
    "print(type(ftr_mat))\n",
    "print(f'크기', ftr_mat.shape)\n",
    "print(f'단어집합(사전)', cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 3,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1,\n",
       "        1, 1, 1, 1],\n",
       "       [0, 0, 0, 4, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 0, 0, 4, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 6,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr_mat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 한글텍스트에 대한 카운트 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "크기 (4, 9)\n",
      "단어집합(사전) {'나는': 3, '배가': 7, '고프다': 0, '내일': 4, '점심': 8, '뭐먹지': 6, '공부해야겠다': 1, '먹고': 5, '공부해야지': 2}\n"
     ]
    }
   ],
   "source": [
    "text2 = ['나는 배가 고프다', '내일 점심 뭐먹지','내일 공부해야겠다','점심 먹고 공부해야지']\n",
    "\n",
    "cnt_vect = CountVectorizer()\n",
    "cnt_vect.fit(text2)\n",
    "ftr_mat = cnt_vect.transform(text2)\n",
    "print(type(ftr_mat))\n",
    "print(f'크기', ftr_mat.shape)\n",
    "print(f'단어집합(사전)', cnt_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftr_mat.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어 수치화: 카운트 기반"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단어 표현:\n",
    "- Local(국소): 해당 단어 그 자체만 보고 특정 값을 매핑하여 단어를 표현\n",
    "  - 원핫벡터, BOW(카운트기반: 문서단어행렬(DTM), TFIDF)\n",
    "<br>\n",
    "<br>\n",
    "- Distributed(분산): 주변 단어들을 참고하여 해당 단어를 표현\n",
    "  - Word2Vec, FastText, Glove, LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문서단어 행렬(Document-Term Matrix: DTM)\n",
    "- 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현\n",
    "- 각 문서에 대한 BOW를 하나의 행렬로 만든 것\n",
    "- BOW와 다른 표현 방법이 아니라 BOW표현을 다수의 문서에 대해서 행렬로 표현하고 부르는 용어\n",
    "- 서로 다른 문서들을 비교할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 피처벡터화 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Matrix is everywhere its all around us, here even in this room. You can see it out your window or on your television. You feel it when you go to work, or go to church or pay your taxes.',\n",
       " 'You take the blue pill and the story ends.You wake in your bed and you believe whatever you want to believeYou take the red pill and you stay in Wonderland and I show you how deep the rabbit-hole goes.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크기: (2, 52)\n",
      "인덱스:\n",
      " {'the': 39, 'matrix': 23, 'is': 20, 'everywhere': 12, 'its': 22, 'all': 0, 'around': 2, 'us': 42, 'here': 16, 'even': 11, 'in': 19, 'this': 40, 'room': 31, 'you': 50, 'can': 7, 'see': 32, 'it': 21, 'out': 26, 'your': 51, 'window': 47, 'or': 25, 'on': 24, 'television': 38, 'feel': 13, 'when': 46, 'go': 14, 'to': 41, 'work': 49, 'church': 8, 'pay': 27, 'taxes': 37, 'take': 36, 'blue': 6, 'pill': 28, 'and': 1, 'story': 35, 'ends': 10, 'wake': 43, 'bed': 3, 'believe': 4, 'whatever': 45, 'want': 44, 'believeyou': 5, 'red': 30, 'stay': 34, 'wonderland': 48, 'show': 33, 'how': 18, 'deep': 9, 'rabbit': 29, 'hole': 17, 'goes': 15}\n"
     ]
    }
   ],
   "source": [
    "tfidf_v = TfidfVectorizer()\n",
    "tfidf_v.fit(text)\n",
    "ftr_mat = tfidf_v.transform(text)\n",
    "print(f'크기:',ftr_mat.shape)\n",
    "print(f'인덱스:\\n',tfidf_v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13847566, 0.        , 0.13847566, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13847566, 0.13847566, 0.        ,\n",
       "        0.        , 0.13847566, 0.13847566, 0.13847566, 0.27695132,\n",
       "        0.        , 0.13847566, 0.        , 0.        , 0.09852657,\n",
       "        0.13847566, 0.27695132, 0.13847566, 0.13847566, 0.13847566,\n",
       "        0.41542698, 0.13847566, 0.13847566, 0.        , 0.        ,\n",
       "        0.        , 0.13847566, 0.13847566, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13847566, 0.13847566, 0.09852657,\n",
       "        0.13847566, 0.19705315, 0.13847566, 0.        , 0.        ,\n",
       "        0.        , 0.13847566, 0.13847566, 0.        , 0.13847566,\n",
       "        0.29557972, 0.29557972],\n",
       "       [0.        , 0.47350659, 0.        , 0.11837665, 0.11837665,\n",
       "        0.11837665, 0.11837665, 0.        , 0.        , 0.11837665,\n",
       "        0.11837665, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11837665, 0.        , 0.11837665, 0.11837665, 0.16845192,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23675329, 0.11837665,\n",
       "        0.11837665, 0.        , 0.        , 0.11837665, 0.11837665,\n",
       "        0.11837665, 0.23675329, 0.        , 0.        , 0.33690384,\n",
       "        0.        , 0.08422596, 0.        , 0.11837665, 0.11837665,\n",
       "        0.11837665, 0.        , 0.        , 0.11837665, 0.        ,\n",
       "        0.50535576, 0.08422596]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toarray -> transform 보는 방법\n",
    "ftr_mat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크기: (4, 9)\n",
      "인덱스:\n",
      " {'나는': 3, '배가': 7, '고프다': 0, '내일': 4, '점심': 8, '뭐먹지': 6, '공부해야겠다': 1, '먹고': 5, '공부해야지': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.57735027, 0.        , 0.        , 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.57735027, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.52640543,\n",
       "        0.        , 0.66767854, 0.        , 0.52640543],\n",
       "       [0.        , 0.78528828, 0.        , 0.        , 0.6191303 ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.61761437, 0.        , 0.        ,\n",
       "        0.61761437, 0.        , 0.        , 0.48693426]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = ['나는 배가 고프다', '내일 점심 뭐먹지','내일 공부해야겠다','점심 먹고 공부해야지']\n",
    "tfidf_v2 = TfidfVectorizer()\n",
    "tfidf_v2.fit(text2)\n",
    "ftr_mat2 = tfidf_v2.transform(text2)\n",
    "print(f'크기:',ftr_mat2.shape)\n",
    "print(f'인덱스:\\n',tfidf_v2.vocabulary_)\n",
    "ftr_mat2.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유사도 행렬 계산\n",
    "- 문장 간의 유사도 계산\n",
    "- 매트릭스와 transpose한 매트릭스를 곱해 유사도를 계산\n",
    "- 자기자신과의 곱은 1, 유사하지 않을수록 0의 수렴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영문 문서들간의 유사도\n",
    "doc_dist = ftr_mat * ftr_mat.T\n",
    "\n",
    "# 한글 문서들간의 유사도\n",
    "doc_dist2 = ftr_mat2 * ftr_mat2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.24065636],\n",
       "       [0.24065636, 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dist.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.32591355, 0.25632484],\n",
       "       [0.        , 0.32591355, 1.        , 0.        ],\n",
       "       [0.        , 0.25632484, 0.        , 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_dist2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부해야겠다', '점심 먹고 공부해야지']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COO, CSR 표현 실습\n",
    "- COO(Coordinate) 행렬:\n",
    "  - 비어 있지 않은 요소의 행, 열 및 해당 값의 좌표를 저장\n",
    "- CSR(Compressed Sparse Row) 행렬:\n",
    "  - 행의 시작 위치를 나타내는 인덱스 배열과 값 배열로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([[0,0,1,0,0,5],\n",
    "              [1,4,0,3,2,5],\n",
    "              [0,6,0,3,0,0],\n",
    "              [2,0,0,0,0,0],\n",
    "              [0,0,0,7,0,8],\n",
    "              [1,0,0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0이 아닌 데이터\n",
    "data = np.array([1,5,1,4,3,2,5,6,3,2,7,8,1])\n",
    "\n",
    "# 행 위치\n",
    "row_pos = np.array([0,0,1,1,1,1,1,2,2,3,4,4,5])\n",
    "\n",
    "# 열 위치\n",
    "col_pos = np.array([2,5,0,1,3,4,5,1,3,0,3,5,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Coo표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_coo = sparse.coo_matrix((data,(row_pos,col_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 5],\n",
       "       [1, 4, 0, 3, 2, 5],\n",
       "       [0, 6, 0, 3, 0, 0],\n",
       "       [2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 8],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_coo.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 5],\n",
       "       [1, 4, 0, 3, 2, 5],\n",
       "       [0, 6, 0, 3, 0, 0],\n",
       "       [2, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 7, 0, 8],\n",
       "       [1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
